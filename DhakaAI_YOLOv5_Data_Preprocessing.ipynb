{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DhakaAI YOLOv5 Data Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hisham32/DhakaAI-yolov5/blob/master/DhakaAI_YOLOv5_Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Qz_FhO0ATN"
      },
      "source": [
        "<img src=\"https://dhaka-ai.com/static/images/logo.png\" align=\"center\"/>\n",
        "\n",
        "In this notebook I am going to show you how you can process the original dataset given for the [Dhaka.ai Challenge 2020](https://dhaka-ai.com/index) to train and generate submission files from the Starter Code given on the host site. As this is the first Machine Learning Comptition in Bangladesh, it will be a bit tough for the undergraduate students to catch up with bits and pieces of data pre processing in this object detection and localization competition. My notebook is for those who are willing to participate but don't have a deeper understanding of data pre-processing. Once you are able to run the basic train and submission, you can gradually study the starter code and tweak it to improve. Good Luck !\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Notebook Author:<br>\n",
        "\n",
        "Md. Redwan Karim Sony<br>\n",
        "Lecturer, Dept. of CSE,<br>\n",
        "Islamic University of Technology [(IUT)](http://www.iutoic-dhaka.edu/) <br>\n",
        "Email: [redwankarim@iut-dhaka.edu](mailto:redwankarim@iut-dhaka.edu)<br>\n",
        "Kaggle: [@redwankarimsony](https://kaggle.com/redwankarimsony)\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<h1>Table of Content:</h1>\n",
        "\n",
        "1. [Data Download](#1)\n",
        "2. [Data Cleaning](#2)\n",
        "3. [Convert .xml to .txt](#3)\n",
        "4. [Resizing all the Images](#4)\n",
        "5. [Train and Validation Split](#5)\n",
        "6. [Creating Metadata:](#6)\n",
        "7. [Saving the Processed Dataset](#7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlPymajh8onk"
      },
      "source": [
        "<a id=\"1\"></a>\n",
        "##1. Data Download: \n",
        "First of all you need to download the original data hosted in the [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/POREXF) repository. For simplicity I just downloaded it and put it on my google drive. You can simply download the data and unzip it into an usable form just by running the follwoing cell of code.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY42OAorw38G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8bFzz3ghCXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155ec231-8a9c-4f41-ee29-5cb041907508"
      },
      "source": [
        "# Connecting colab to google drive for uploading data to colab \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIdoeBJ5LPxk"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import os, glob\n",
        "\n",
        "\n",
        "# Downloading the dataset\n",
        "!gdown --id 1GIiqqmqEPSiGBb1MU1kIZG4q7BOIzqik \n",
        "!unzip traffic-dataset.zip; rm traffic-dataset.zip;\n",
        "clear_output()\n",
        "\n",
        "# There was .rar file inside .zip file. So we unzip them again !\n",
        "!unrar x train.rar\n",
        "!unrar x test1.rar\n",
        "clear_output()\n",
        "\n",
        "# Removing rar files that we no longer need. \n",
        "!rm train.rar\n",
        "!rm test1.rar\n",
        "\n",
        "# Removing unnecessary demo data folder from workspace.\n",
        "!rm -r sample_data\n",
        "\n",
        "# Renaming raw data folder to remove space. Trust me, it makes life a lot easier :D \n",
        "%mv 'Final Train Dataset' train_data_raw\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgtvDau3w4yN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkWn0aCgJPe0"
      },
      "source": [
        "<a id=\"2\"></a>\n",
        "## 2. Data Cleaning:\n",
        "At the time of initial coding, I found some problem with three of the images. They had two categories of problem. \n",
        "1. Train image files <font color=\"red\">`Pias (359).PNG` </font> and <font color=\"red\">`Pias (360).PNG` </font> are actually  `JPEG` files but somehow they are named with extention `.PNG`. So the height and width attribute in the corresponding xml labels are 0 as automatic label generator could not read the image properly. \n",
        "\n",
        "2. One of the label files <font color=\"red\"> `231.xml` </font> is actually a `.txt` format label but labeled as `.xml` file. However for the inconsistency of the label index in that file, we will simply drop label and image together. \n",
        "\n",
        "\n",
        "To avoid the problem, simply we will remove these three problematic files and process rest of them. The follwoing code cell will remove them and their label file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMREr76RMtLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a938ae-510b-4288-e4e4-9f63278617a2"
      },
      "source": [
        "corrupt_files = ['231.jpg', '231.xml', 'Pias (359).PNG','Pias (359).xml', 'Pias (360).PNG', 'Pias (360).xml']\n",
        "\n",
        "%cd /content/train_data_raw/\n",
        "\n",
        "for file in corrupt_files:\n",
        "    file_path = os.path.join('/content/train_data_raw/', file)  \n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        print(f'{file} is removed successfully')\n",
        "    else:\n",
        "        print(f'{file} is already deleted')\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/train_data_raw\n",
            "231.jpg is removed successfully\n",
            "231.xml is removed successfully\n",
            "Pias (359).PNG is removed successfully\n",
            "Pias (359).xml is removed successfully\n",
            "Pias (360).PNG is removed successfully\n",
            "Pias (360).xml is removed successfully\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gyC9HkkEz00"
      },
      "source": [
        "<a id=\"3\"></a>\n",
        "## 3. Convert .xml  to .txt\n",
        "Now in the follwoing code cell, we define a function <font color =\"blue\"> `convert_xml2yolo()` </font> which will covert `.xml` format label file into `.txt` format file with the same name. \n",
        "\n",
        "\n",
        "Here is the required format of labels for YoLo V3: (for one image one text file)\n",
        "* One row per object\n",
        "* Each row is `class index` `x_center` `y_center` `width` `height` format describing a single bounding box. \n",
        "* Box coordinates must be in normalized `xywh format` from [0 - 1]. If your boxes are in pixels, divide `x_center` and `width` by `image_width`, and `y_center` and `height` by `image_height`.\n",
        "* Class numbers are zero-indexed (start from 0).\n",
        "\n",
        "\n",
        "The annotating process generates a text file for each image, contains the object class index and coordination for each object in it, as this format `(object-id) (x_centre) (y_centre) (width) (height)` in each line for each object. Coordinations values `(x_center, y_center, width, and height)` are relative to the width and the height of the image. Below are the formula for conversion. \n",
        "\n",
        "* $x\\_center = \\frac{(x\\_min + x\\_max) }{2(image\\_height)}$\n",
        "* $y\\_center = \\frac{(y\\_min + y\\_max) }{2(image\\_width)}$\n",
        "* $height = \\frac{(x\\_max - x\\_min)}{(image\\_height)}$\n",
        "* $width = \\frac{(y\\_max - y\\_min)}{(image\\_width)}$\n",
        "\n",
        "Where the image is denoted like: \n",
        "\n",
        "![bounding box3.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmEAAAERCAYAAAAzP3AXAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AACAASURBVHic7N13fBTV+gbwZ7aX9J6QHhKS0FvokMTewILdq6jgz3Ltgtd6wSt2xYIodkWwi73SERGR3mtoSSC9b7LZ3ff3x4ZgTAIJKZOQ5/v5vAqzM7Nnl03y5MyZcxQAAiIiIiJqVxq1G0BERETUFTGEEREREamAIYyIiIhIBQxhRERERCpgCCMiIiJSAUMYERERkQoYwoiIiIhUwBBGREREpAKGMCIiIiIVMIQRERERqUCndgOo7fj76/HOe0kI72bEnj02LFpUiC+/yEVOjl3tphEREXV5ze4J69PHA5eMD8I55/ojMsrUFm2iVnLGmX7omWzFW29lobjYgUf/G4P9B4bjrbcTERHJfzsiIiI1NbknzNdXh3ffT8bYCwJQVu7E4kWFWLWqBM88vR8OB9cA74iKix3Yvr0cr83KBADoDQrGjg3AI4/EYNPmFNw0aTs+/SRH5VYSERF1XXKiCgzUy7oNKeJwpskjj0aLt7f2hMe0VwUG6uX9Ocny+uwe4uOjU709Hal0OkX8/PT1tuv1ikx/MlYczjS58qpg1dvJYrFYLFZXrBP2hAUGGbBwUT8kJ1sx8cbteO/d7BMd0q6eeDIOu3fZUFbmgMLbDOpwOAQFBdX1tldXCx56YC8cDsFbbyVh06YybN5UrkILiYiIui4F7jTWIKNRgyXLByBlsBduvnk73pyd1Y5Na5pbbu2Gy68Iho+PDv36/Kl2czoVnU7BwsX9IS4gLXUtpNFPAhEREbWFRrvJHnk0WlySLtOfiFW9y+54NWKEtwwa5Nluz2exaFR/za1Vg1O8xCXpMmyYt+ptYbFYLBari1XDD0RGmaS8IlU2bRkiRuOpEzpao+yONBl7YUCDj5lMGvn0s14S193c5u0YMcJH9HqlxedZvzFFXnolQfX3lcVisVisrlSNjqKaPDkSZrMGDz6wB1VVrsZ2a5LJUyJxyfjAFp2jI9m8qQzDh/s0+FhcdzPGjw/C8OHebd6Ov/4qQXW1tPg8ixYWYtTItm8vERERHdNgCPPw0OKaf4Vg85Zy/PB9foueICXFC0891R1eXqfOvLDLlxdj7NgA6HRKvceOTtfhdLY8HJ1IS8PxUWvWlCA52Qq9vv7rISIiorbRYAi7eHwQvL10eOftrCaHCaNRg8zsEbhkfFDtNr1ewYyX4vH7yuI2v6vytNN90auXtU2f46hZsw4hNsaEiZPC6j1m0Lvf0srK1glIzaXXKzj//IA623x9dTAYGg9Y+/ZVwWDQICjY0NbNIyIiohoNhrDLLwuCwyn45OMjTT6R3e7Ctm0VmDMnGVFRJmg0Cl6b3QO9e3ngpknbW3zn3Zln+SE1teFLgABwyy3hOO0Mv5Y9SRPt2F6BmTMz8d+pMfV6+BJ6mAEARUWOkz6/l5cOe/cNx3UTQhrdZ8Gi/rj6mvqPDx/uja+/7VPbS9enjwf27huOmbN6NHqu4qLq2uclIiKi9lEvhFmtGqSn+2LZ0iJkZzd9jUER4ILzNiArqwoPPRyNCdeH4rprQ3H55ZuxbWvL5qDy89Pjo497YcL1oQ0+bjRqcMaZfshtZE1Ek1mDW28Lb1Eb/unx/2VAq1HwyKPRtdu8vHS46+5IAGg0dP7r2hBMnhJZ+/fLrgjC+g0pCAzU12675toQREeZMKC/Z4PnCAzUIy3NF+HhxnqPVTsECgCDQYFOp+D12T3g7aVDQryl8Rej8DIkERFRe6vX9ZGYZIXRqMGKFUXNPpnN5sLs2Zl44MFoXHRRIF5+5RB+/KH+mLI33kzEsmVF+HDOYQBAdLQJ+/ZVNnre52d0h6+PDkuWNtymmFgzPD202NpI2LvrrgjccGMY+vSxwlbpwqyZh7Brl63Zr+/vioocuPPOnZjzYU8EBuqRkVGJiZPCUFJ6/B6w6U/EIbybEfO/zMXu3Tbcdms4+vTxwFVXh+ClFw8CAMZfEggRIDSsfsgCgEGDvaAAWLas/vthNLpztU6nwUUXByBliBd++rkA8fHmRtvk7+/+GBTk15/YlYiIiNpGvZ6w4JpxQQcPVp3UCX/6qQA+3joUlzgw9dG9De7Tv79nbS/PjZPCsDdjeKN3E0ZHm3DVVe7Lbjt3VDS4T3CwuxcpN7d+iNDrFdx1dwS6x5kxarQP0tJ88ceqQeh+nFDSVB/NO4Lzzt2AgAADRo/xwfTH92H8RZsBuCdC9fKuf3mvsNDdxpBQIwIC9Rg+whsVFS6kpfkCAHokWjB6tA9WrixGt24Nh7D4BHev1uZNZfUes1q1AACLRYOp02Lw6ac5eOnFg4iLNTd6vqAgAxwOQT5DGBERUbupF8I0GvelKbu9+QPLY2NNmD+/NwRAQYEDZWXORvc9usTQpJrB7f4B+gb3u/OuCOzY7u7hstkabtPAQV4oKKjGkcP1L0dGRZkQFOgOljfesB0pg1Zj1y4bXp3Vo1Wuwv38Uz7OP28DTktbh9dfy4S3jzsEPf9CPKKjTPX2nzHD3dvl66vD+RcEQFGAD+dmo0eiBTqdglmv9cCqVSV4550s9O7t0eCA+iEpXhA0PPi/V28P5OTacdfdEQgJMeChB/diz253eA0NbXjgfUKCBXszbFyInYiIqB3VC2Eul9T8v3kn0moVzP+6D7Kyq3Dp+E0YNNATw0c0PJD+aADr2dOKlMFeKK9wIq57/Z4pX18dbrghFM88cwAAEBTUcFDz8dbiwIHKBkPE0XCXX1CNv1aXwG4X/PvfO3H66X5Irel9ai39+3vg3XeTAQDjL96EjRvr91TN+/AwKqtcSOhhwa23huOXnwvw1+pShIQYcN/kSKSkeGHSxO1YsrgIHh5aDBhYd1xYWJgRY8cFwG53NThH2MABHgCA++6LxP1TdiNjr612KovGItaoUT5Y+XtxC145ERERNVe9EHb0B3tze4lS03yQeciO88/diPlf5mLNmlJMnhzZ4L6K4q6bb+2GQ5lV+OyzHNxxR0SdwekAcOPEMBw8VIWP5h1BXn41kpIanoLis89yEZ9gQb9+HvUe69XbvW3L5vLakPbX6hIs+LUA1zcy0L+5tFoFt98ZjhW/D4LG3RGGffsaHnNmtws2bijDzTd3w6CBnnjxxYNYtLAQJpMGTzwRhzvv2ImtW8uxd68Nu3bbcPrpfnWe55VXE/DJJzlYv75+wAMAvV6DoEADvv02D7Nfd6/1WVLiRE6uvcExXxERRqSn++Ljj3Na+C4QERFRc9WZQr9nL6u4JF0efCi6WVPvBwcbRKs9toTOFVcGi8OVJj0SLfX2XbtusLz3frKUlI2RBx+KloAAvezcPUx+XzVI9Ab3OSxWrRzMHCETJ4UJAFm2fIDMeq1Ho8+fnGwVi0Vbb/urryaIS9Ll40961tn+3HPd5dcF/Vq85IBWq8is13pItTNN7rwrQu66O0JsVanHPebb7/uKS9Jl0+Yhte/ZuAsD5NoJIXX2e+bZ7rJtx1AZMNBThg7zli/n95ZFS/qL2ayRwEB9g+fuP8BDHns8Vjw86r4XOl3Dyxu9MjNB/lo7uNHHWSwWi8VitVnV3aDTKZKZPVKWLhvQohPr9Yrs3jtMZr+ZWO+xtesGS1HxaCkpHSP+/joBIElJVqmyp8m117mDyFNPx8nWbcfWrZz/VW/56OOezW7Hu+8miUvS5aWX666NOHVajHz7XZ8Wv4EPPBgtTle6/Kum3Q88FC35haOPe8z8r3qLS9Jl4k1hx93P21sncz/qKQcOjZA//hwk902ObNV1PHv1skpFZaqMHMXFu1ksFovFUqHqb3x8eqw4JV2Se1pbdPJ/3x4u5RWpEhJqqLN97brB4pJ0ef6F+Drb33wrUXbvGSZ33BkulfZUGTnKp/axt95OksVL+je7DbfeFi4uSZex4+ouuH3flEj57PNeLXp9I0Z4i8OZJo9Pj63d9uRTcXIwc8RxjzvrbD95YUa8GAzq9T4ZDBpZtXqQPPxItNofQBaLxWKxumrV3xgYqJfi0jEN9mI1p6xWrezYNVTen5NcZ/vGzUOk3JYqof8IZz6+Ovnhp36SVzBKrpsQWuexSy8LEltVqiQm1b+8ebzS6xVJGeIlGk3dwDN2XIBMeyy2Wef6Z333fV/ZuHmI6PXHzv3iS/GyY9dQtf9Rj1uKAnnxpQR58qm4OpeQWSwWi8VitWs1/MAjj0aLrSpV+vXzaNETREQY5YEHo+uMOcorGCUfN/PSokajyD33RsqQoV5qv2ECuHuSym2p9cbOvfFGoqzfkKJ6+45XI0b6yOgxPqq3g8VisVisrlxKzR/qMRgUfPlVHyT2sOCKyzfjr79KG9rtpKSm+eLQoUrsbuGs9WqKjTVj955hGDduI779Jq92+/sfJCMhwYJhQ/9SsXVERETU0TW6YrPdLrj4wo2YOCkM0/4XC7vdhU2byjDz5UzkNLJGY1MtWVzYouM7Al8/91v3z1nmvb11KC07+cW7iYiIqGtoNIQB7iA269VMzHo1E4B7IWyXs8GOsy5Hq3VPpPbPhbq7x5vx+4r2nfjU00sLfz89SkqdXP+RiIiok6g3WevxVNpcsNsZwgBAU/POyd9SmNWqQUK8BZu3NDyRamsLCTHg1wX9UVg4GnszhiMvbxRcko7x44Pa5fmJiIhag8WigY+PDiNGNrzSzqmqWSGM/s7dE6b8bWmBvv08odMpWP1n642fO563303Caaf5QqNRUF7uRGnNWp2fftYLlzCIERFRJ6DXK/jl1/7IODAcy5cPQExM/XWXT1XHvRxJjcvMrAQAJCZaatddTE31hc3mwrq1bR/C4hMsOOds/9q/W63aOo+/+moCvv8+D5WNLHpOXYdBqyDKpMWuco5VpLq6mbT4b6gXgnQaDDQ1vDYv0V+V1RARXLy7oEXniYw0oW8/D2RlVcFq1SI42IDwCCNGjfLB8OHetWtXv/FmEsornDhyxI6cHDsOH7bjr9UlWPVHSWu8nA6FIewkHTxQhc2by3HV1SF4951sAMDo0T5Y+UcxKivbPvj8fZ3MAytKkLG0BENvDYHRx/1PGhRkwF1p/ti5sn165ajjmuBvxQWeJqTtycOSkiq1m0MdxLuxvrjO2wL3LfKCcpfgx/IqlHLcL/2NKEB3vRaDTIYWn+uafwXj8cfjGn3c6XIP9QmPMGL/vkp4emhRWKjAXuXCls3lLX7+joghrAVmzDiAt99Owu13hGPuh4cxcpQPnpi+r12eO667pfbPUUsrEPWLDXJDTfhzCCDAk3E+QHbLv3Do1BBr0GKJ2o2gDuODvApkVDowLdgL1x8swvt5FWo3iTqo5yN9MKgVekqfmL4fH32Ug4R4M0JCjbBYNHjiiTh4e+uwY2cFhg75C1u3DcWuXRW4aNwmOLvALwQMYS3wwfuHMWqUD156KQFT7o+CRgN89NHhdnnuQwcra/8sZ3oBfUxASE3g0ilw2FxYu6oEwsuRXV6iQQcfLYd/Ul2LS6qQ5XBiWrAXHP+8zZuojWTstSFjrw06nYKff+0HLy8dtm0vx6FDVSgucuDft+3AJ5/2wp13RuCFFw6o3dw2xxDWAk6nYNLE7ViytAhnnemHDz7IRsbeyhMf2Ap++TkfObl2BAUagEEWAJY6jz8z4wAe/vNIu7SFOrYfE/xxtrXrDHSl5mMEo/ak0yn48qveSEv1xc0370Dfvh6IjzcDAOZ/mYsbb9iG199IxBtvZKKs5oazUxV/PW4hp1PwwXvZuPqqLfj5p5YNWmyOnJxqjBm9FlVH6k6cW1TswHPPH8Bj0zLarS1ERERNcTSAnX9eAO65ZxfemJ1Zb585HxxGdMTvp3wAA9gT1qnt2F6BQ+fuRvfL/fFGVSXmLsjHH38Ucy43IiLqkKbcH1UbwF6ccbDR/XJzW7YyT2fBENbZ2QX4uAhz9+RiWUnX+NASEVHn9MMP+di1qwKffZqjdlM6BIYwIiIiahfr15Vi/TpOnXQUx4QRERERqYAhjIiIiEgFDGFEREREKmAIIyIiIlIBQxgRERGRChjCiIiISDUKAEVRuxXqYAgjIiIi9XTRAAYwhBEREZGK3D1hXTOJMYQRERERqYAhjIiIiEgFDGFEREREKmAIIyIiIlIBQxgRERGRChjCiIiISD1d88ZIAAxhREREpKIuOjsFAIYwIiIiIlUwhBEREZFqPD10qKx0qd0MVTCEERERkWoSkyzYubNC7WaogiGMiIiIVBMUbEBWdpXazVAFQxgRERGpQqNREBCoR15utdpNUQVDGBEREanCy0sLo16DvDyGMCIiIqJ2o9O556dwOkXllqiDIYyIiIhIBQxhRERERCpgCCMiIiJ1dOHZ8gGGMCIiIlJJF89gDGFERESkkpoU1lXXj2QIIyIiIlUoNSmMIYyIiIiI2g1DGBEREZEKGMKIiIiIVMAQRkRERKQChjAiIiIiFTCEEREREamAIYyIiIhIBQxhRERERCpgCCMiIiJSAUMYERERkQoYwoiIiIhUwBBGREREpAKGMCIiIiIVMIQRERERqYAhjIiIiEgFDGFEREREKmAIIyIiIlIBQxgRERGRChjCiIiIiFTAEEZERESkAoYwIiIiIhUwhBERERGpgCGMiIiIVCWidgvUwRBGREREqnI6u2YKYwgjIiIiVUhNF5jDoXJDVMIQRkR0HBHQwAxF7WYQndLYE0ZERHUkKXq83S8es+MikKjo1G4O0SnH6qEFAGRnVancEnXwuwoRUSN8RYMx3YNg0AIRnmZMWb8Xq1GtdrOIThm+vno4HIL9+yvVbooq2BNGRNQogVJzJTI1PhBvDEnAWVqzuk0iOoX4+eqwN8OGykqX2k1RBUMYEVET9YvwxqxR8bjO5Am92o0hOgV4++iwa6dN7WaohiGMiKgZYv0seGZ0HP5t9YGFA/aJWqSgwIF9+xjCiIioiYKsBjw2Ogb3e/vBj99GiU5aVmYV9u5lCCMiombwMOrwwMgoPB4aiEhFq3ZziDqlQ5mVWLq0SO1mqIYhjIjoJOm1Cm4eGIYZ0aFI5s3mRM1WUe7C2jWlajdDNQxhREQtoEDBxckBeC05HEM4XJ+ImoEhjIioFYyO8sIb/SJwroZTWBBR0zCEERG1kj4hFrw6OBw3GKzsEyOiE2IIIyJqRdHeBjw9OAx3WLxg5RQWRHQcDGFERK0swKzDtEEh+I+nNwL4bZaIGsHvDkREbcCq1+D+gUGYHuiLGHAKCyKqj/dUE1Gn0FOrx2NDU2AxGgARQABAAHHV/F1q/v6Pqt3m+tvf0cDfa/YB6hyv0SioebKmUxRABHoFmNTTD8F7dHjoYD62wNFq7wcRdX4MYUTUKaT5+ePic0e5g5KrJjC5XIDLeezPIjX/d9b8/+/b/7afS/6xz9HzOf92jn8ce5IUAONiPOFv1GDK7jysRHXrvSlE1CYsFi3MZg3y89v265WXI4moU9BrOvcg95GhFsxODMJYjYnfeIk6MA8PLbZsHYIjOSPx1NNxbfpc/F5ARNROevsb8EqvANyot8CgdmOIupgJ14fijjvCT7jf6Wf4ISTUgKnTMtC3r2ebtokhjIioHUV66PBkL3/cafaAB6ewIGo3jz0Wi9i4E0+m3KePB3bvsiEm2ownntjXpm1iCCMiamf+Ri2mJvviQasnAvltmE5Rcd3NMBo7zufbP0CPwoIT3xxjtWphq3QiKsaE35a37eLiHefdISLqQiw6BZOTvPCknxdi+K2YTkG/rxyEO+488eW/9mI2aWCrcp1wP60GCAkxoiCv2n0DdQMMBgWBQXokJlng6XnyU9Dw7kgiIpXoFAU3xngALmBiUdv+xk3U3rRaBQZD2/yCodMpcDiaPnWMv797ITGlKSMAFCC8mxG9envgz78GIyDAfWxVlQs5uXZkZ9mRnV2FjRvKsHlTOez2ypN5CQAYwoiIVGV3CXLsJz8FBlFHlXOkCiZz64ew4BADXpvdAxeP29TkYwYM9EROjh063fFTmNWqxeln+AEANm4sw5df5mLvHhtyjtiRm2uHzXbinrTmYAgjIlJJqcOF53YU45WKcrWbQtTqduyowNCh3q1+3iOH7bjhum3NOsbHR4cNG8oQEW6ss/3mW7phzZpSrP6zBACQMsQLVg/35cVp/83Atm1t+7XJgQhERCo4YnPi4a1FeLaiHIXNnZGfqBPYv78S0dGmNjl3UVHDA+z9/fXo1dsKvf5Yj5dGo8DpFGRlVSE45FgIu/e+SMya1QM33hBau23xokJcfKG7h82/5jJkW2IIIyJqZ7tL7bhvawFmVZXDxgDWofS06vFJdz/8lBCAqwIsajenU9u3vxLav6UMrVbBmWf54cmn42C1NjyYPSzMiLnzeuLhR6LrPXbOOf5ITfNt8DitVsG990Vi34Hh2LBhCA4cGoErrgwGAJxxpi/++KMEFeUueNT0cvXr54Gnno5DVlYVjKa6UWjQIPfcYI21sTXxciQRUTtam1uF+3cVYAGq1G4K/UOSRYflcQHwTTBBzvfCmUYFMwsd+P7lLEw/UILtFVz7szlsNhdMZneQCQoy4Otv+yBlsBccToHZpMFdd+6qd8yH83rC4XBh7LgofP11HjZtLKt97K67I2AyaTBmcWG9415+JQGXXRaE6ydsw7ff5KGsYgyio03w9NIiuacVP/9UgPIKJzw8tFAU4NnnuuP3FcXIza2uWR/WTaNRMGGCu2esrXrx/o49YURE7WRRZgVu2pXLANZBvRTuA1+dBvJEKHCdP3CFH3xuCcI1z8dgefdAhBvavmfkVKIox+5GfPudJFitWiQl/oG77tyJK68Kqbd/VLQJqWN8cMP127BjRwWiouqGoKysKvTt51HvuJ69rJh0UxjOPHM9Pv8sB1VVLigKkJ1tx+PT4/DhnMMAgNIyBzw9tBh/WRDS0/0wefJu5OTYER1z7HkuvzIIvr56/PJLAc4+x78V342GsSeMiDqFbSVl2Ln3IDwtJvei2n9fePvoYtuQugt54x+Lff/9ODhrHjt6DvnHOdz7hXgaWzyvvUuAT3eXYGp2AXaAd0J2NHqtgse7eeEMqxEYbgHia34ory8H+lkh53ojYFkZ7i+x4fZ9nEqkqSptLpjNGvTr74nzzvPHqFFrsXNnBSIijQjw18PDQ4uysmNfD541lwpzc+wICzMi54i9zvnKypywWt09WX+fv+u0032x4rdirFtbCgDoHm+GRlEweowPtm8rR26OexHu0lIn/Pz0eHVmD8yenYk/V5UgIFCPSTeFITTUAKNJg5dfSsANN2xz7zerB7y8tCgpabuvWYYwIuoUfrGVYvx7n8GibUpvhDT4xxMfUnfnCJcG8y4ZBH0LrhlUuQSvb87Hs4XFyETr3t5OrcOiADf4uMd/yRArAKBwWwX2XL0Xg6aEAdf5Q+4MROSXeWo2s9PJy6uGp4cO100Iwa7dFfh9hTvAbtxQBpcIUoZ4YdHCY5cW7dXur7+LLg6C1arFpk1ldc5ns7mgwD34Pi+vunZ7eDcT9u23wWjUIP00Xzw+PRbVDsFpp/ni37fuOHZ8hQshIQZs31GBKZN3AwAWLShEcbEDb7+bjKQkC77/IR/ffpMHD08tnnuuOy69PBhvv5nVVm8RQxgRdQ4uAJucdrRnR5L2ZJfZrvk1vcTuwrMbcjGzrARFHIDfYRU7BL+UV+EqL7M7kQHwFQWDHu0GXO6eMwqhBsgQM1B/GBM1Yv36UigKcNGFgfjp54La3qvc3Grs31eJhB6WOiFsz24btm8vx7x5PbF5SznOvyAAv/9ejMxDVdDpFETHmJCWtg7FxXXH5s169RCeez4eS5YPwO+/FeOqK7Zg2/aheGN2Vp15vVwuQXW14MorNtf2wFVWunD1VVsxaVIo3n0nC888fQAAUFbqxMWXbEJqqk+bvkcMYUREbeBweTWmrz+CtyrLUckA1uHlO90/rJVMh/tfK9kMJJuhbK2AJJoBjYL83m0/UPtUknmoCuUVTkREmLBgQUGdx7Kyq6DV1r3Q73QKQkKNmD8/F7m51bj++jA88mgMDhysxLat5ZjxwkGs/L243vPs21eJ8Zccm7j15ZkJAIAvPs+ps9+bb2Th7bey4XLV/Xr8+ad8/PxTfr3zLl9ahOVL2/byM0MYEVEr21lYhakbDuMzRwV4P13n8EtRJW73tQJ/lQMIdG88WAXpYQb2VQGxJqw/YFO1jZ2NiDuIxcdbsOIfC2HP/fAIDIb6oy3HX7IJe/fYsG/fyS0FNHZcAG671b1eZWZW/Rtg/hnA1MYQRkTUiv7KLsf9m7KxiHdAdirfFVXiruxivAhvYKvN3RMWUTOxZ6wJO3dWYM7cI+o2shN6+un96NvXA9nZdQfZz349s8H9/355srniupvx7rvJ+GttCWKizSgr7fg3wTCEERG1kl/3FGPKrsNYj+oT70wdzkuHy/BdcSVuPK8UN48Lgk+SBZUiuOHrLMxfXIiqKt5Y0VzvvpPdLs+j0ymY82EyfvutCMuWFWHSTWHt8rwtxRBGRNRCLhF8tDkPjx08gp2cgqJT22Nz4MF9JZgxqwzneZmwtrIaG8ubH6p1OgUi7nFO1PYuvzIYPZM9kHjRSlxxVXDT74pWGSdrJSJqgSqHCzNWZWEKA9gpJbfahffyK5odwAwGBZ9/0RvlFakoKR2DH37si/GXBtUbhE6tR1GAu++OwHvvZyM72w6jQYNqR+dIYQxhREQnqajSgcd+P4D/5echiwGMAJhMGgwZ6oVXZh7ExInbUF7uxLyPeuLnX/rB15cXn9rCqNE+6N/PE6/OPAQA8PXVo7ysc3w9MoQREZ2ErOJKPLQ8A8+XFKK4s1z76KSGDffGCzPi8cKMeAwe7KV2c46rpMSJc85ejx3bK/DRvCO4dPxmpAxajZgYE+Z/3afBOwKpZf7zQDS+/S4PO3dUAAB69LBg964KlVvVNAxhRETNtD2nHHeu2Is3bCWoYgBrM2azBq/O6oGlywYgz6Tb0AAAIABJREFUNNSAykoX7psSiX9dV3/dwY5k86ZyvPnGsVnW168vw9gLNmJAf0/ce1+Uii079cTEmnDWmX6Y8cKB2m0hoQYcyuwcdyezb5SIqBlW7S/ClDUZWMYpKNpUt3Ajvvq6D0JCDDjj9HVYuuTYPFMWS+frP9iypRxTp2Zg2mMxmPNBNg4d4uenNZx2uh/y86ux4rdjk7jm51UjMPAkV7toZ53vk0xEpJKftubg/9bsYQBrYxGRJixfPhAulyBl0Oo6AQwAKio651QRr848hJwcOybfz96w1pKUaMWWreVw/G0gfmZmFcLCjCq2qukYwoiIGqXA6RI4XYIPVh/A7dv2YQPnAGtTJpMGX3/TB7l5dpyevq7eJJ+dWVWVCy+/dAjXXhsCs5k/fluD2aypNwg/O7sKoaHsCSMi6tQyFQe+XHsQ05fsxOT9mdgtXISord1+RwRiYky49JLNKO0EM54312ef5cDbS4fBKR37BoPOwlbhgpeXts62AweqEBllgk7X8W+CYAgjImrEfnFiQsZ+/Dc3Bzly6gWCjsZk0uCeeyMw44WDOHCgaWsHmlTsUdLrFXTr1rzLXlmZVSgucSA6mouBt4at28rRq7cHDIZjn4Ply4vg463DgAGeKrasaRjCiIiOgxcf289FFwfCz1ePt97MOu5+yclWfPFlb+Tmj0JFRSp+/2Mg4uLMdfbpkWhG1uGRuOnmli9fc8ut3eDtXf8+tueej8cffw5q9vmqqlwwGPnjtzX89FM+zGYNHno4Gsaa9zQ7qwouEQQE6lVu3YnxU0BERB3CpElh+PbbPGRlNX7jg4+PDgsX9cfevTaccdo6hAT/ht+WF+GnX/rB09N9WcrTU4tvvu0LBcCav0pb1CZPTy1efbUHLhgbUO+xcRcGYPcu28mdmDObtIrMQ1W47dYdmDw5Ejl5o/Db7wPx19rByM6y17ljsqPiFBVERKS6qGgTxqT64rxzNxx3v7HjArBhQxkm37e7dtt/7t+LgQO9cOPEMLw44yCenxGP8HATRo1cg7VrWhbCysqcyM+vRrfwupcddToFEeGmk16g2sUQ1mreeTsbP/6Qj9PP8EPv3h6w2Zx4+61sFBd3/DGcDGFERKS6wYO94HQKliwpPO5+Go2C1X+V1NnmcgnmfXQEV14RDEUBJt4Yhief3NfiAAYAIsDSJUVIHeOLp5/cX7s9JMQARQGKTuIHvaIoEKawVpWdbcecDw6r3YxmYwgjIiLVBQUbkJ9fjUrb8ecA27mzAlVV9fdZvLAQb76RiGHDvQEAP/5Q0Gpt+/GnfMx8NQHduhmRWTMTe0SEe2B9RXndGzaiokz417UhOONMP0REmHDksB1ffJGDV2cegq3mtVmtWpR1krUNqW1xTBgREanO5RRotSeeUmDjhjIsXFi/tywo2D0Ie9myIthsLvz1j96ylvjk4yPIzrLj08971Q7Qj4pxh7Dc3GpoNArOv8Af333fF7v3DsNt/w7Hxo1lmDY1A08+tQ+VlS4EBbnnrfLz08Ni1uDw4VNn/jM6eewJIyIi1eXnV8PXRwe9QUG1vfFLdWVlznq9SBaLFq+9lohDmVXYsL4U3cLc60y2lrIyJy66aCN++KEv1qwbjJdfPoTkJCsA4HB2FRYu7ocxo32xYkUxJkzYii8+y230+ZOTrRAAW7eUt1r7qPNiCCMiItVlZFRCq1UQHWXGrl0VTT5Op1Pw9ruJ6NvXA9On70N+fjUiIk0nDHPNtWF9GQYNWo2HH4nBI49Ew99Pj2qH4Otv+qC83IWzzlqPX3858SXQAYM8sXevDfn5nPwEAC68KABfzc9Tuxmq4eVIIiJS3fZt5bBXuzB4SPNmkn/q6ThcflkwyiucmPXqIfz0Yz68vXQ46yy/Vm9jdpYdt92yA6HBv+GHH/Kh1ynYsrUcgwevblIAA4BRI306xdQJ7eXscwKadBn6VMUQRkREqisrc2LFb8UY18B8XI2JijbhrrsjAADPPH0A2dl2bN9egUWLC/HfqbGwWrUnOMPJOe/8AJx7rj927KjAuWdvQH5e03q1jEYN0k/zxfffd92en38KCTbAYum6UaTrvnIiIupQ5s07grFjAxDWxKWAwrsZoVEUrFlbimeePjZ9xF137kRMtAkbNqbg9jvC683x1RIDB3lizofJAIBffy1o1tizc871g1YL/Phjfqu1p7OzWDRdejHzrvvKiYioQ5k39zBy86rx4EPRTdp/zZpSTJ22F+eft6HOtBWbN5Vj0MDVWLSoEI8/HouDB0fgUNYIrPh9IN55NwkRkY2HsgcfisZZZzd8KdNi1eLDuT2RkVGJKrsLuXlNv8NRp1Nw/3+i8d672Sg7BRcmP1kWixZmS9v0WHYGHJhPREQdgs3mwiOP7MUbbyTizTcysWF92XH3r6x04bGp+xp8bN++Stw0aTvuuH0nevayIiTEgNJSJ9avK0VJScMh6J57I3HpZUF4843MBh+/775IxMaaMWTwaiz7bSAczZin9f9u7oboKBPOP8GKAF2NuyeMIYyIiEh1c+ccxlVXBWPeRz0xYtgaFBW1bOmZykpXk9aPvOjiQFx+RRBOS1uHgoL6Y7wMBgV33BmOD97PxvqacKg0cTz58BHeePKpOIwfv4l3Rf6DxaLlmDAiIqKOwOEQXH3lFmi1Cn76pR8CAvTt8rypab4484z1DQYwAEjoYYGfrx6ff55Tu60pISw8woh583rixhu34ZefWm8W/1OFxaqFpQtfjmQIIyKiDiUvrxppY9ZCp1Pw15rBOP+Cpt8xebLuvH0nio/T6+bp6b5wVFjY9J45nU7BB3OScc89u/DZJzknPqALYk8YERFRB5OdbcfIEWvw7rvZ+Oijnvj0814ICzOo3aza3i8RHHd+K0UBHngwGrNnZ+HLL3LbqXWdj9WqabOpRDoDhjAiIuqQKm0uTJuagaTEP1BU6MDvfwzCxElhqkzuKeKefV+jcT93QX41ggIbv1Qa192MLz7PwScfHWmX9nVWBoMGBgMnayUiIuqQDh2qwk2TtqNXz1VwOAXRNYtnt6fSmmkl/P3dwWv9+lIMGeLd6P67d9mwdSvXhzyRrhu/3BjCiIioUygrdeK9d7KxZ7et3Z97184KFBU7cM65/gCAH37Mx4CBnujT16Pd20KnDoYwIiKiE7DbBZ98cgT/uiYEaWm++Gt1KZxOwX8eiFK7aZ2e0tS5Pk5BnCeMiIioCf43LQPnnO2PhYv6127r2dOqYos6N5PJ3Q/kcIjKLVEPQxgREVETZGXZ0TN5FYYO84LZrIWIYOPG48/qT40Lrbnb9ciRpi//dKphCCMiImqi8nInFi4oVLsZp4SkRHcv4vbtXfcGBo4JIyIionYXFW1CUbEDuTlddyknhjAiIiJqd0aTBjabS+1mqIohjIiIiNqdTqd06UH5AEMYERERqUCrVeB0MoQRERERtbujy0F1VQxhRERERCpgCCMiIqL2JzXVhTGEEREREamAIYyIiIjaHTvCGMKIiIhIDSJdPoUxhBERERGpgCGMiIiI2h0vRzKEERERkRqYwhjCiIiIqP0xgzGEERERkQpEjv6n62IIIyIionYn0uUzGEMYERERqaOLZzCGMCIiImp/wnnCGMKIiIhIBV08gAEMYURERESqYAgjIiKidmcya2C3u9RuhqoYwoiIiKjddQsz4fBhu9rNUBVDGBEREbW7xCQLdmyvULsZqmIIIyIionYXGWnCrt02tZuhKoYwIiIiandGowblFU61m6EqhjAiIiJqdxoNIK6uPU8FQxgRERG1O40G6OIZjCGMiIiI2p+iKFw7Uu0GEBERURfFEEZERETUvqSrd4OBIYyIiIhUwAzGEEZERESkCoYwIiIiIhUwhBERERGpgCGMiIiISAUMYUREREQqYAgjIiIiUgFDGBEREZEKGMKIiIiIVMAQRkRERKqQLr5uEUMYERERqUJcardAXQxhRERERCpgCCMiIiJSAUMYERERtbvGFvDu398Tvy7sD51Oad8GqYAhjKgr6KbDgPN8MSbVBwYDv+yJqP2FdTPiw7k9ERioB9BwCBud6oMFC/vjj5XFcDhO/UH7/G5MdArT6xV0ezAE8k0cbno7AYsXD8CmLSlI7mlVu2lE1MX06mXFVVcF49bbwmu3KRrgoosD0b27GWed7Y8ffuiHb77NxdT/ZqjY0vbDEEZ0Cvv0897odV0woABlZU489NBeHDpUhXffS1K7aUTUxfy2vBj5+dUYM8andpu4gPlf5sLHV4+PP+6JlSuL8X+TdsDpPPV7wQCGMKJTksWiwTvvJWHc2IDabd4eWkyfHovDh+0YPMgLQUEGFVtIRF1NRYUTzz57AKPH+ODZ57pDUQCNRoFWq+Cpp+NQXS245uotsNvd81aYzRp062ZEt3Aj/AP0p+QYMYYwolPQh/N6YsJ1oSgrc2LdTXuh/FqMKRduwbZt5bjyimAAgH+AXuVWUkfxXoQvws1atZtBXcBLLx7EmjWluOfeSISGGGAwKLjhxlCkp/li8dJCPPpoDP5cPQg5+aOwYdMQzHgxHjff0g1nn+MPf/9T73uWTu0GUOu4JcgDV/p38VnvCACgtWgwblwgAMDqoUVIsQBP5KByjw1G07Hfu/Jy7Wo1kToYvaLAS6MB4FS7KdTBHO180ioKzvI24ufiqmafIzzCiAvGBuD22yOQ2MNSu13RKJg9O7H275deEgQAcDgFBYXVqLA54eOnQ2ysGRaLFrt3VuDIkVPr+xZDWCdX4nJfN7/C06xyS6jD0ANSLYBegQIg9IlukAVleGpMOKwxxz4nPr465OZWq9dOUt2BKifml9lwkYcZk4M9MMB06vU00MnTAIjWa3HY4YJJUaDXnNzlwF9+6YfERCvKK5woLKqGr48eNpsLWh2we5cN0TFm3DRpGxYsKITTIaiwOWGr6BqdCgrQxRdu6uQGeOgx0KSHt1aDAAMvJ5Bb3H3BuOSO8AYfq6x0obTUibjY31FWxp6Pri7crMXBxBAUOV3w0Wqwv9qJtVWnVm8DnbwchwsJBh0Gm/Tw3JB9UueIjTXjX9eGwNNTiy1byrFuXRm2binHpZcFYdGiQmRnNb937VTBEEZ0ikpKsmBQiheqqwVZmVWIT7AgIECP4mIHfvg+Hwf2V6rdROoAgo1aHEgKxpelldheUY2fy6rwRylDGB0z0KrHaE8jZhwuU7sppxyGMCIiIiIV8O5IIiIiIhUwhBERERGpgHdHEhE1UXy8Gb5+7jsI83KrsX9/ZZeZ2ZuIWh9DGBFRE5x1tj9+/LFvnW2HD9vx7Xd5eO+dbPzxR3GDCxITETWGA/OJiJogKcmKzVuHYEjKajidQHi4EWee6YeLLwlEaIgRK/8oxn/u34Ply4rUbioRdSLCYrFYrBPX2+8kicmkqbNNb1Bk/KVBsmFTijhd6fL8C/GiNyiqt5XFYnX8Yk8YEVETKQoaveSoNyi4//4oTJ0ag/lf5eHKyzfD4eC3VyJqnBbAVLUbQdRRnXa6HyZPjkRWth2HszmBJTXO5QSWLSvC7j02PPhgNFwuYOlSXprsCry8dJj6WAzWrClFZWXXWG6HWgenqCBqgI+PDvM+7okvvuyF7MN2nH9BgNpNolamnNwyeCc0b+4RvDjjAB58KArx8VzTtSs48yw/3D8lCmef7a92U6iTYQgj+oehQ72wZu1gxMdbMHDAavxvWgZmPH9A7WZRE5jNGlitx19DNSTEgFWrB2HV6sF1tickWHDjxDB4eLR8DdbHpmWgrNSJu++JbPG5qOM7etn5n5eqH58ei7/WDm7gCCI3hjCivxl/aRAWLxmAhYsKMXrkGuzZbQMALnTdQWi1CnS6hruwLr0sCBn7hmP1msGN7qPTKfj0s17QKArWryut81haui/efDMRGzcNQf8Bni1qZ0mJEx99dATjLw2CXt9GXW7U7s451x+79wyDxVL3R6fd3vAlyNBQI/r390Rcd/aIUsMYwohqjB7jgw/nJuPRR/fiponbYbNxbEdHoNG4Q4zRqMHKVQOx78BwREaZ6uxzzb9CMO+jnpg/PxcJCWYMGtxwiLrqmhAMH+GDgQM98d13eXUem/16JkYMX4NNm8vw8y/90LevBxQFuOrqYHwwJxlPPR2Hfv09mtzub77JQ4C/Hr16N/0Yal9WqxaXXh7U5P3Hjg1AbKwZFkvd3tKjod/Ds+52EYEC4Oabu7W4rXRqYggjAhAcbMDcuT0xd+4RPPtM57r0GBiox7PPdcevC/ph/le98fY7SUgZ4tWkY318dPD2ab05mwcN9sIZZ/o1+NgNN4birrsjmnW+eydH4qdf3BOkPvRwFHokWGDQa3DOOcfG3iT3tOL12Yl44D97cMvNO7Dy9xJcfHH9H6yKAtx7TwS++SYXAHDJJfX3WbmyGJeN34w//yzBV1/3wTPPdsdrryUiK6sK69eXITur6TdnrKvpaevd29qs10ztR1GAp5/p3uhn9p8io0woLnEgP7+6zvbgYAMAICnR0uBxsbHsCaPGqT5PBoulZhmNGln220BZtz5FLBatWCzaJh/bq5dVxo4LkG7djG3axoAAvcTEmuttHzbcWzKzRsj6jSny8KMxcsONoTJ2XID4+uoEgLz9bpLsyRguaem+9Y69554IsVWmSn7BaAkI0LdKO+9/IEoO54wUQwPzZP26oJ9U2FLF07Pp7+9vKwbKkmUDZHCKl1Q70uSGG8Nk/cYUuXdypAAQRYEsWjJAfv61n2i17ue8b3KkbNk2tN65+vTxEJekS89eViksGi1Z2SNFo2l4Pi9PT61s3jpEnJIu6afVf++aUnq9Ii5Jl9v+Ha7q55t1/DrnXH95fHpsk/b9feVAWbZ8QO3fJ9wQKl982Vt27RkmLkmXQ5kj5Lvv+8pXX/eRD+Yky9p1g8Ul6TLvo54CQE473VfGXRig+mtmdahSvQEslqr1yswEyS8YJd27m8XDQyvDhnuf8BhPL63M+7inVFalyq7dw6SiMrX2h+3AgZ5y+x3h8uDD0bJgYX/R6Zo2ceeAAZ4y7bEYUZS62888y0/yC0ZJYfHoOtsHp3hJYfFo+WBOshiNmgbPee99kfLrwv5SVZ0mk24Kq91+3YRQqbKnydXXhMgtt3aTESN9WuW9TEq2ikvS5dzz/Os99vU3fcQl6RKfYGnSuaKjTbJ2XYosXzFQPvu8lyxeOkAUBbJ23WCZ8p+o2vem2pkmyT2ttcfFdTeLS9IlMbHu80yeEilbt7vD2QsvxotL0iXhOG1ZvKS/OFzp8sCD0Sf1XkRGmsQl6TL+0iDVP+Os1ql9B4bL3HnuQKXXK1JSNkY++ayXzP2op7gkXVauGiRnnOknaem+cu55/rJhY4oUFY+W8y8IkFtu7SZOV7o4nGkSE2tS/bWwOkyp3gAWS7W68qpgcbrSZWwzfjvVaBRZunyArFg5sLZ36owz/cRWlSrT/hcrDmeabN4yRIqKR8uChf3rhSrAHYKWrxhYZ9t77yeJS9KlXz+P2m1nne0nFbZU2btvuBzJHVW73dNLKxn7hsunn/WqDXlX/ytENm8dUif0He0duvW2blLtTJOp02IkuadVSkrHyF13R7TJe7p6zWD5/oe+9bZ/Ob+3O4TF1+/Ra6hMJo08/nisrPpzkJSWj5EbJ7pD5G8rBsr0J2JFUdx/PvpD8e+1dn2K/OeBqDrb5s7tKR/Ode/r7aMTl6TL8hUDxWqt3zM3OMVLikpGy733RYjdkSZDhng1+324YWKYOCVdIqP4A/dUKINBkarqNPnq6z6128ak+sg55/rL7XeEi0vS5fMvetc5ZuOmFPlyfm+ZcH2oOCVdfvy5nzglXf59O3tHWbWlegNYLFXK318v+QWj5Jln45p1XFSUSXLyRtX74f3rgn7idKXLlClRMnqMjxSXjWnwEiIAefChaHFKunh762q3ZewfLg5Xmlw3IVQASESESfILRsus13rIy68kyJJlxy6DTJkSJZnZI8XT61gbUlN9xSXpMjil4cBw8SWBUlo+RopLxsgX83s3eimupTXuwgBxSbpcdkVwne2vz04Ul6RLdHTTQ8n/Ho+V4tIxUl6RWnvJdOasBFm4qL9cPD5I7I40SUyq35t1zz0RkrF/eJ3LrEuWDpCnn3H/W5vNGnFJuuzOGCY//9qv3lJEn37WSx5+JFoUBfLV171l5apBtYG2qfX1N33kj1WDVP+cn0yFhRll6fIBMnVajOptaWnpdIps2zG0Xu+sTqfI1deEnPD4YcO9ZdXqQVJYPFpcki57M4bV2+eGiWFSXplae9kRgFgsWql2psmcuclSXpEqX33TR/R6RdauGyxff9OnRa+JdeoUB+ZTl3X1NcEAFEybuq9Zxzldgl07K1BefmzaCpNJg8QkK5YsKURCohnzv+qDW/5vOzL22ho8R26uHQrcc1MBQESEEVGRJhQWOhAUpAcAPPFkLA4crMRdd+5ETIwJu3ZW1B4/9sIAzJt7GKUlx9pQVXObfEiIocHn/PKLXDz+v33w9NQiKMgAq7Vtvvy//ioPH39yBC+/FI/Q0GNtOZLjHtReUtL06T6q7C54emgxd95h5OW5B0P/tboUAwZ44uWX4vHaa4ewfVtFveNmzjyEFSuKsW59CibeFAa9QYHBoKCi3P0eRUS4764875wN8PfT47MvesNsdr8fsbFmDBnqhRkvHIQIcO89u9G3jwduvrXpd7gFBRlwxpl++PLL3CYf01EEBOix/LcBCAww4Kcf89VuznHt3D0MTzwVd9x9evWyokeCBWFhxjrbk5KtmDMn+bjTkaQM8cLPv/RDZmYVfvg+Hw6nIDrajKjounfnVtqcKCl21JmqwtNTC61GwWWXBaOszInrr9uK6mrB4iVFGDrc+yRebdvz9NLil1/74Yorg9VuSpfBEEZd1rBh3li8pLBOmGqKrEw7Jk7cXmfb+MuC0C3MiOHDvREXZ0ZS4krMm3uk0XNkZFQCAEJqQsqFFwWiwubCrp0VCAsz4qyz/XDV1SGYMnk37HaBl7cOJcWO2uNDQw3YtbtuwLv4kkAAQPppvo0+b3i4Ec88ux+hIQbM+7hno/NptdS/b92J4hIHli4biMuvCMaE60MxaWIYAKBbuPEERx9zNLD9+MOxMFBQUA1vbx0KCqrx4H/2Nnic3S645qotSE9fh4L8asTFmiEAlJrveJddHoTNW8qxY3sFUlPX4sgRO35e0B9hYQbk5Nhx8UWbaj8Xe/bY8H83b8fzz8fj0anRTZpp/7oJIVAAfPB+dpNfa0eg0Sh4461EVFa6kJKyGn/8UaJ2kxrl5aVDXKwZ+prPsK+vDg89Eg1f37p3+x6dIiQrq6rO9m1by3Ekx177i9A/WSxafPhhMhYuKsRl4zfDaNRg5sxDqK4WjBzlU2dfs0WL3btsqKqS2m1HPyd6nYK3385EYaH76zcjwwYf79a7I7k1iQuIiDRhzofJ+O/UGM5x105U745jsdSoVX8Okmee7d4q53rt9R7iknTZtGVInUuMjVVauvvS4SXjg8RgUGT3nmHy7ntJ8tIrCfLHqkFy4OAIeevtxNr9ly4fIM8+d6ytn3/RW37+pV/t+K8RI32kuHSMzH4zUcrKU2XAQM8Gn/f1NxLF00srvftYpahktDz636ZfbtJolGbdBRocbJBPP+sllfZUKS4dI59/6R4Tlpra9JsAYmNNsmPnUElMOjbw3tNTK48/ESdhYc27I/WLL3vL9z/0lXvui5RKe6pcfElgncfDwozSu7dHo8f36eMhy5YPkMjI419ONZs1sv/AcPlgTrLqn/Hm1m3/DpdKe6qkDGn489ORanCKl7gkXR55NFoAyPtzksUl6fLe+3Xf95tv6dboTRgff9pLhgxt+PL9gw9Fy5HcUeLvr5fEJIuU21IlNtYsCxf1l/feS6qz731TIuWdd5PklZkJtdusVq1UVqWKS9KlT59jn6uhw7zFJekSE9MxxwpaLBp5bbb7+9kffw6S0WN8GhzXymq1Ur0BLJYqtWFjijz2v6bdmn68Skv3lZzcUeKSdElKtjbpGP8AvbgkXS69LEhunBQm1c406dHDIhNr/nwoa4R4eR0LcwsX95fnX4iv/XtSslXyCkbJwsX95ZWZCVJRmSpT7o8URYFMnRYjGfuGS3Cwod7z/v0uwnPP85dyW6rcfufxBwnr9YrcfU+E7N03XHbvHdbonZiNldGoiE6nSPd4912Ll18RLCazpt44rLauESN9ZNeeYbJ7zzD517UnHgt0snXv5Eipqk5r8l2gHaH0ekWmP+G+qeSuu9rmho3WrnPP8xeXpMsVVwbLtRNCxCnp8va7SVLtSKvzdXjzLe67Em+YGFb/HOcHiMHQ8Ofw95UDZfoTcRIcbJC161Pk2efdvwTd9H9hkl8wSvxrxhuOGOEtgwZ7ycxXE+TpZ+r+UvfAg9Hy2uwedUKMokAe/W+MdO/etBtU1KpxFwZKxv7h4pJ0Wbykf6vdQc2qV6o3gMVSpb79rk+dgbQnU+ec6y+2mt92K2ypEhjYtPm2rFatuCRdbpwUJvsODJc5H7p/e7/lNvddVtdOqBsSZrwYL6v+rDvIOzbWLDNfTZCPP+klp53uV+exa68LkdFjTvxNs1cvq7w6q0ejg841GkXmftRTDh8ZKROuD212APt7GQzuW/oXLx0gW7YPlfPOrz+NRWevmFiTlJSOkRdmxKvelqbUrbd1k0f/GyPffN9HyspTZcL1oe323FqtIlarViyWk/tMnXOuO4RNuD5UKipT5fEnYkWrVWTlqkHy86/9aueq+/yL3vLJp72aPVXIosX9ZcXKgZJ9eKTMndezNqwZDIp8810fWb1msFx5VbCcf4H7zuqEBLNcdHHgSb2WxsrDQys+Pjrx9m64fHwaKF93+R4tP534+end5e+uwEC9DBrsJf93Szd54ok4efJVBOl0AAAGeklEQVQpdz31dJzc/rc7N41GjdxwY6js3ecOY+s3pqj+mT3VSqn5A1GXM/n+SEy+Lwrh3X6D3d78L4PgYAM2bR6CgAA9MjJsUBQF9moXHvjPHnz3bR6qqxs/p9Goga0yFXn51dAowID+q3HgQCXiEyy48sogTH98P5zOY8eHhBjw2ee98dJLB/H5Zzkn9XpPxpln+eHVWT0wZvRaZGVWnfiA4/D01GL7jqEIDTXivPM21BnndSowGjVYvHQAfH11GDhgNSqaOdawvaWkeOG3FQNrxwWuXFmMtWtLT3BU82g0CrRaBd7eWsR1tyAszACzWQuzWQOjQVM7bqqyyoWKCicefmgvXn8ts0nn7pFowbZtQ1FdLViwsADjLtgIh0PQp68Hfl3QH7t2VmDBwgLcf38Uxo3biF9+KmhW2/v198Dtt0dgyZJCzP3wCFyuY1+PGo2CwSme8PLUYcGCgnoLd7eGsDAj9h8cDq2mbcdllZQ64PrbCm1ZmVUY0P9P2O0CRQGuvS4UM2bEAwpw37278c7bWW3anq6GIYy6rOgYE3btGoZrrtmCTz5ufrB5+pnumDw5Erm5dqSnr0NJsQMvv9IDF4wNQFFhNX79tQA//pSPX38uQHZ2/eVu1qwbjKhIE8aP34Qli4ua9Jxms6Zd17ScdFMYvvk6D0eONH25noacc64/Zs3qgbBuRjgdAl+fZaiqOnXW5tRqFbz1diLGXRiIUSPXYMvmcrWbdELXTgjFM8/EobjYAYtFi7AwI47+uC8tc7r/zVuYLkQAh0NQXOJExl4bDh2qRHm5ExUVLthsLlRWutyPFztQUeHEurWlyM2tPvGJa9w3ORLBwQZMm5qBsrJjoTcyyoT7749CfLwZK1cW47Fp++r8UtMZaDQKbr2tG6weWrhcAqfz/9u7n5im7zCO40+ppVA0uGkNSAAVnOjQKIMJZZBtaKImaLadtzkTF2N2nNltRI1LdIct0RkDBw1yWdxJuGy6xS0x/gEsRj2QCTIXs1q6RQPjT2Z/zw51aLHEdvjz2199v5JPCL/TN02gT76/7/d5RCxLxbJErGjsZzSqEn2sOJz+ba4z/BK1VP64MynB4IiEw4k/74KCbDnWWiHNzQuloyMkn+25KaHQ7P4PIDHj23GEmEr7yVX660Bd3PmrZHP4yCt6JVijlavjz4EVl+Toh9sL9auvl0+9tti7b9kTr/J8vqyURvg4MT6fW4+fiDWhbW2r0Hff86s1i1FA6Zq9+5fq3fAbGqh/+rSFdE1ZWa5+3rJUL3VXq6Vv67mfq7SyMrkzjiSzUlqao7eGAhq8+ro2NHIWzOYYXwAhxuJflK2/3Q7oD2fXpjQzkjw9Xm+WnvulSscn3tTtO2JnjXJzs/Sve43a9tjNT6dn58eL9eZAXcKmsU7NylV5evBQuQ4MBfTQl+UJpwqQzExRkVfP/rROP9pRqB6PPQ2dSVyML4AQo1m9Zq7e/r1ee4M1umyGDvck9XzycJTL9JFQx0+s1LvhmYdnOynNWxfqxe7qhDdRMyEej0s3bHw5qc7y5PnH7XZpVdU8bdrw7HaWy5fnzuoCDkk5xhdAiPH4/R493bVGhyMNCYdPk9Tz/Zm1ernnybE9u3bH+jYtcnjhEqjP16PHVmT8K2WSvnG5Ysca2MV3buiYD4jI8PA/8s62a9LSMignO16VU99VyuYtC8Tr5U/k/8rLc8uDBDdE/7s16M12djfu/v4x2b2rX0ZG0vsWJDKXqsjYWOxmKZyJbxjgoWhU5eg3d6S0+Ly0t4dkRYVPPt1TIouLkh+zg0e6uiJSW5svxSXxn58d1/lN+DOS/C0+AEgkPQdYAQaNjkal83TE9DIcr6szIl8cKJNNmxZIWyu9hQBgOnbCANjixvW/ZWBwXLZu88c9T2YANgC8CCjCANhCVaSzMyJNTS9J/nz31HMXVRgAiAhFGAAbnfo2LDneLHn/g8KpZwUF2SIicR3OAeBFxNgiALZxuUTO/LhOql+bJ+vX98j9ew/kwsVqCYUmpa621/TyAMAoijAAtlqyJEcuddfI5IQlc+a4JG+uW5reuiI9Pc92WDQAOA2vIwHYamhoQrZs7pPBW+PS1zcqjQ29FGAAIOyEAQAAGMFOGAAAgAEUYQAAAAZQhAEAABhAEQYAAGAARRgAAIABFGEAAAAGUIQBAAAYQBEGAABgAEUYAACAARRhAAAABvwLOPwrWQ2eCbAAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYo_cAgPMTa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bab36f4-46bb-4a23-f979-703222477b72"
      },
      "source": [
        "\"\"\"\n",
        "Thanks to @bjornstenger for his excellent code for converting the code from XML format to .txt format\n",
        "here is the original link of this cell of code.\n",
        "Original Link: https://github.com/bjornstenger/xml2yolo/blob/master/convert.py \n",
        "\"\"\"\n",
        "\n",
        "from xml.dom import minidom\n",
        "\n",
        "# Remember these number assigned. These are the label indexes which will be used in the training process.\n",
        "# Feel free to unfold to see what's inside \n",
        "lut={\"ambulance\": 0,\n",
        "     \"auto rickshaw\": 1,\n",
        "     \"bicycle\": 2,\n",
        "     \"bus\": 3,\n",
        "     \"car\": 4,\n",
        "     \"garbagevan\": 5,\n",
        "     \"human hauler\": 6,\n",
        "     \"minibus\": 7,\n",
        "     \"minivan\": 8,\n",
        "     \"motorbike\": 9,\n",
        "     \"pickup\": 10,\n",
        "     \"army vehicle\": 11,\n",
        "     \"policecar\": 12,\n",
        "     \"rickshaw\": 13,\n",
        "     \"scooter\": 14,\n",
        "     \"suv\": 15,\n",
        "     \"taxi\": 16,\n",
        "     \"three wheelers (CNG)\": 17,\n",
        "     \"truck\": 18,\n",
        "     \"van\": 19,\n",
        "     \"wheelbarrow\": 20\n",
        "     }\n",
        "\n",
        "label_count ={}\n",
        "\n",
        "print(f'Object Names: {list(lut.keys())}' )\n",
        "\n",
        "def convert_coordinates(size, box):\n",
        "    \"\"\"\n",
        "    This function converts the coordinates. \n",
        "    box: (xmin, ymin, xmax, ymax)\n",
        "    size: (width, height)\n",
        "\n",
        "    returns a touple where (x, y, height, width) of the boundary box\n",
        "    \"\"\"\n",
        "    dw = 1.0/size[0]\n",
        "    dh = 1.0/size[1]\n",
        "    x = (box[0]+box[1])/2.0\n",
        "    y = (box[2]+box[3])/2.0\n",
        "    w = box[1]-box[0]\n",
        "    h = box[3]-box[2]\n",
        "    x = x*dw\n",
        "    w = w*dw\n",
        "    y = y*dh\n",
        "    h = h*dh\n",
        "    return (x,y,w,h)\n",
        "\n",
        "\n",
        "def convert_xml2yolo(filelist, lut ):\n",
        "    \"\"\"\n",
        "    filelist: list of .xml file paths to convert to .txt file\n",
        "    lut: a dictionary containing class_name to class_index mapping\n",
        "    \"\"\"\n",
        "    for fname in filelist:\n",
        "        xmldoc = minidom.parse(fname)\n",
        "        fname_out = (fname[:-4]+'.txt')\n",
        "\n",
        "        with open(fname_out, \"w\") as f:\n",
        "            # print(f'processing{fname}')\n",
        "\n",
        "            itemlist = xmldoc.getElementsByTagName('object')\n",
        "            size = xmldoc.getElementsByTagName('size')[0]\n",
        "            width = int((size.getElementsByTagName('width')[0]).firstChild.data)\n",
        "            height = int((size.getElementsByTagName('height')[0]).firstChild.data)\n",
        "\n",
        "            for item in itemlist:\n",
        "                # get class label\n",
        "                classid =  (item.getElementsByTagName('name')[0]).firstChild.data\n",
        "                if classid in lut:\n",
        "                    label_str = str(lut[classid])\n",
        "                else:\n",
        "                    label_str = \"-1\"\n",
        "                    print (\"warning: label '%s' not in look-up table for file '%s'\" % classid, fname )\n",
        "                # get bbox coordinates\n",
        "                xmin = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('xmin')[0]).firstChild.data\n",
        "                ymin = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('ymin')[0]).firstChild.data\n",
        "                xmax = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('xmax')[0]).firstChild.data\n",
        "                ymax = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('ymax')[0]).firstChild.data\n",
        "                b = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
        "                bb = convert_coordinates((width,height), b)\n",
        "                #print(bb)\n",
        "\n",
        "                label_count[classid] = label_count.get(classid, 0) + 1\n",
        "\n",
        "                f.write(label_str + \" \" + \" \".join([(\"%.6f\" % a) for a in bb]) + '\\n')\n",
        "        # print (\"wrote %s\" % fname_out)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object Names: ['ambulance', 'auto rickshaw', 'bicycle', 'bus', 'car', 'garbagevan', 'human hauler', 'minibus', 'minivan', 'motorbike', 'pickup', 'army vehicle', 'policecar', 'rickshaw', 'scooter', 'suv', 'taxi', 'three wheelers (CNG)', 'truck', 'van', 'wheelbarrow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE0TCNlVPY-c"
      },
      "source": [
        "Now Let us create the path list of the `.xml` files to convert them to `.txt` files. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dJTNvisMLco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b722a1-2b8e-4319-cb5d-8e183f8e196b"
      },
      "source": [
        "# Reading Image file paths\n",
        "formats = ['jpg', 'jpeg', 'JPG', 'png']\n",
        "image_file_list = []\n",
        "for format in formats:\n",
        "    image_file_list.extend(glob.glob(f'/content/train_data_raw/*.{format}'))\n",
        "\n",
        "# Reading XML label file paths\n",
        "label_file_list_xml = glob.glob('/content/train_data_raw/*.xml')\n",
        "\n",
        "print(f'Image files found: {len(image_file_list)} \\nLabel files found: { len(label_file_list_xml)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image files found: 3000 \n",
            "Label files found: 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvzdnCHfb71t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9zm5FGxb8Xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8c2fc1-63f6-4afa-a94a-58df78600a90"
      },
      "source": [
        "print(\"Number of images in the folder\")\n",
        "!ls -1 train_data_raw/*.jpg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the folder\n",
            "2843\n",
            "Number of annotations in the folder\n",
            "ls: cannot access 'train_data_raw/*.txt': No such file or directory\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dZsVaW3LWsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7eb192-448f-421e-ebe8-ab20c09c262d"
      },
      "source": [
        "# Converting .xml file to .txt file\n",
        "convert_xml2yolo(label_file_list_xml, lut)\n",
        "label_file_list_txt = glob.glob('/content/train_data_raw/*.txt')\n",
        "print(f'XML --> TXT files: {len(label_file_list_txt)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XML --> TXT files: 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMZ4cDicDmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780beadd-eb4d-4516-9af0-0405af1e693f"
      },
      "source": [
        "print(\"Number of images in the folder\")\n",
        "!ls -1 train_data_raw/*.jpg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the folder\n",
            "2843\n",
            "Number of annotations in the folder\n",
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTfW7OJ7TfRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055ab00b-ba78-4667-f321-ed1ff97808ac"
      },
      "source": [
        "label_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ambulance': 70,\n",
              " 'army vehicle': 43,\n",
              " 'auto rickshaw': 372,\n",
              " 'bicycle': 459,\n",
              " 'bus': 3333,\n",
              " 'car': 5476,\n",
              " 'garbagevan': 3,\n",
              " 'human hauler': 169,\n",
              " 'minibus': 95,\n",
              " 'minivan': 934,\n",
              " 'motorbike': 2284,\n",
              " 'pickup': 1225,\n",
              " 'policecar': 32,\n",
              " 'rickshaw': 3536,\n",
              " 'scooter': 38,\n",
              " 'suv': 859,\n",
              " 'taxi': 60,\n",
              " 'three wheelers (CNG)': 2989,\n",
              " 'truck': 1492,\n",
              " 'van': 756,\n",
              " 'wheelbarrow': 119}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plmPskQacFCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2219cb89-a342-4989-9931-94baac2829ac"
      },
      "source": [
        "print(\"Number of images in the folder\")\n",
        "!ls -1 train_data_raw/*.jpg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the folder\n",
            "2843\n",
            "Number of annotations in the folder\n",
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud8eLlhcu6-Q"
      },
      "source": [
        "## Data Visualization: \n",
        "Let us have a look at the existance of the labels in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV-PUUqquxmh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "e994c0cb-9803-4325-bc10-28af3c52e9ed"
      },
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# DataFrame Generation\n",
        "df = pd.DataFrame({'labels': label_count.keys(), 'count': label_count.values()})\n",
        "df.columns = ['labels', 'count']\n",
        "df.sort_values(['count'], ascending = False, inplace =True)\n",
        "df.head()\n",
        "\n",
        "# Plotting\n",
        "fig = px.bar(df, x=\"labels\", y='count',  color=\"count\",\n",
        "    orientation='v', \n",
        "    title='Frequency of the Labels in Dhaka.ai-2020 Challenge', \n",
        "    color_continuous_scale=px.colors.sequential.Viridis_r\n",
        ")\n",
        "fig.update_layout(title_x=0.5, xaxis_title = 'Labels', yaxis_title = 'Label Count')\n",
        "fig.update_xaxes(tickangle=60)\n",
        "fig.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport pandas as pd\\nimport plotly.express as px\\n\\n# DataFrame Generation\\ndf = pd.DataFrame({\\'labels\\': label_count.keys(), \\'count\\': label_count.values()})\\ndf.columns = [\\'labels\\', \\'count\\']\\ndf.sort_values([\\'count\\'], ascending = False, inplace =True)\\ndf.head()\\n\\n# Plotting\\nfig = px.bar(df, x=\"labels\", y=\\'count\\',  color=\"count\",\\n    orientation=\\'v\\', \\n    title=\\'Frequency of the Labels in Dhaka.ai-2020 Challenge\\', \\n    color_continuous_scale=px.colors.sequential.Viridis_r\\n)\\nfig.update_layout(title_x=0.5, xaxis_title = \\'Labels\\', yaxis_title = \\'Label Count\\')\\nfig.update_xaxes(tickangle=60)\\nfig.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFHQm_c-XGJu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c55ADid-XHH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d60500a-7469-4d58-9d7e-de753ae30f4e"
      },
      "source": [
        "print(\"Number of images in the folder\")\n",
        "!ls -1 train_data_raw/*.jpg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.png | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.JPG | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.jpeg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the folder\n",
            "2843\n",
            "Number of annotations in the folder\n",
            "12\n",
            "Number of annotations in the folder\n",
            "143\n",
            "Number of annotations in the folder\n",
            "2\n",
            "Number of annotations in the folder\n",
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joWrtBu3VWQr"
      },
      "source": [
        "<a id=\"4\"></a>\n",
        "## 4. Resizing all the Images (Optional)\n",
        "If you observe carefully, you will see that images have different sizes. They are not uniform. The following code segment visualizes that nicely.  <font color=\"red\">It seems that 3000 images has 430 different resolutins. </font> Here the follwoing segment of code shows that we have some high resolution images which we have to downsampled to $(1024x1024)$ and some images which have lower resolution than $(1024x1024)$ should be upsampled. \n",
        "\n",
        "😃😃😃 <font color=\"green\"> Since yolo v3 uses relative bounding box parameters, we changing the aspect ration will have no effect on the bounding box placement. So we dont have to change the labels after we resize the images.  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVoQKxQMzLLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b9c12e-fe8a-4571-bd04-c017e3b10ce4"
      },
      "source": [
        "from PIL import Image\n",
        "img_sizes = {}\n",
        "\n",
        "for fname in image_file_list:\n",
        "    img = Image.open(fname)\n",
        "    img_sizes[img.size] = img_sizes.get(img.size, 0) +1 \n",
        "img_sizes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(352, 399): 1,\n",
              " (352, 401): 1,\n",
              " (352, 404): 1,\n",
              " (352, 405): 1,\n",
              " (352, 421): 1,\n",
              " (352, 426): 1,\n",
              " (352, 429): 1,\n",
              " (352, 432): 1,\n",
              " (352, 435): 1,\n",
              " (352, 436): 2,\n",
              " (352, 437): 1,\n",
              " (352, 438): 1,\n",
              " (352, 439): 2,\n",
              " (352, 443): 1,\n",
              " (352, 444): 1,\n",
              " (352, 445): 1,\n",
              " (352, 448): 1,\n",
              " (352, 454): 1,\n",
              " (352, 456): 1,\n",
              " (352, 458): 1,\n",
              " (352, 460): 1,\n",
              " (352, 461): 1,\n",
              " (352, 462): 1,\n",
              " (352, 467): 1,\n",
              " (352, 469): 2,\n",
              " (352, 472): 1,\n",
              " (352, 476): 1,\n",
              " (352, 478): 1,\n",
              " (352, 479): 3,\n",
              " (352, 482): 1,\n",
              " (352, 486): 1,\n",
              " (352, 488): 1,\n",
              " (352, 490): 1,\n",
              " (352, 491): 1,\n",
              " (352, 492): 1,\n",
              " (352, 493): 1,\n",
              " (352, 496): 1,\n",
              " (352, 498): 2,\n",
              " (352, 502): 1,\n",
              " (352, 506): 2,\n",
              " (352, 507): 1,\n",
              " (352, 509): 1,\n",
              " (352, 511): 2,\n",
              " (352, 512): 1,\n",
              " (352, 515): 1,\n",
              " (352, 517): 1,\n",
              " (352, 524): 1,\n",
              " (352, 526): 1,\n",
              " (352, 527): 1,\n",
              " (352, 537): 1,\n",
              " (352, 543): 2,\n",
              " (352, 545): 1,\n",
              " (352, 547): 1,\n",
              " (352, 586): 1,\n",
              " (407, 539): 1,\n",
              " (431, 576): 1,\n",
              " (451, 587): 1,\n",
              " (490, 654): 1,\n",
              " (491, 654): 1,\n",
              " (491, 656): 1,\n",
              " (492, 655): 1,\n",
              " (530, 667): 1,\n",
              " (540, 359): 1,\n",
              " (560, 750): 5,\n",
              " (600, 400): 1,\n",
              " (640, 352): 40,\n",
              " (640, 360): 207,\n",
              " (640, 400): 1,\n",
              " (644, 362): 2,\n",
              " (644, 483): 1,\n",
              " (684, 383): 1,\n",
              " (687, 493): 1,\n",
              " (690, 450): 1,\n",
              " (700, 367): 1,\n",
              " (700, 400): 1,\n",
              " (703, 533): 1,\n",
              " (710, 882): 1,\n",
              " (720, 960): 14,\n",
              " (720, 1280): 10,\n",
              " (725, 400): 2,\n",
              " (730, 1095): 1,\n",
              " (749, 416): 1,\n",
              " (750, 412): 1,\n",
              " (760, 770): 1,\n",
              " (768, 576): 2,\n",
              " (768, 772): 1,\n",
              " (777, 529): 1,\n",
              " (790, 452): 2,\n",
              " (800, 371): 1,\n",
              " (800, 450): 2,\n",
              " (800, 600): 1,\n",
              " (816, 612): 4,\n",
              " (854, 480): 253,\n",
              " (861, 358): 1,\n",
              " (864, 1305): 1,\n",
              " (892, 674): 1,\n",
              " (900, 471): 1,\n",
              " (900, 472): 1,\n",
              " (900, 576): 1,\n",
              " (900, 600): 3,\n",
              " (901, 419): 1,\n",
              " (923, 801): 1,\n",
              " (927, 620): 1,\n",
              " (933, 474): 1,\n",
              " (940, 454): 1,\n",
              " (941, 465): 1,\n",
              " (948, 441): 1,\n",
              " (950, 340): 1,\n",
              " (954, 360): 1,\n",
              " (956, 476): 1,\n",
              " (957, 499): 1,\n",
              " (960, 540): 2,\n",
              " (960, 639): 1,\n",
              " (960, 640): 9,\n",
              " (960, 646): 1,\n",
              " (960, 711): 1,\n",
              " (960, 720): 1,\n",
              " (960, 960): 2,\n",
              " (980, 972): 1,\n",
              " (989, 525): 1,\n",
              " (989, 577): 1,\n",
              " (997, 485): 1,\n",
              " (1000, 541): 1,\n",
              " (1000, 603): 1,\n",
              " (1000, 668): 1,\n",
              " (1000, 750): 1,\n",
              " (1008, 727): 1,\n",
              " (1023, 685): 1,\n",
              " (1024, 572): 1,\n",
              " (1024, 650): 1,\n",
              " (1024, 658): 1,\n",
              " (1024, 668): 1,\n",
              " (1024, 683): 4,\n",
              " (1024, 713): 1,\n",
              " (1024, 769): 1,\n",
              " (1024, 771): 1,\n",
              " (1043, 763): 1,\n",
              " (1053, 717): 1,\n",
              " (1058, 624): 1,\n",
              " (1065, 1599): 1,\n",
              " (1080, 1919): 3,\n",
              " (1080, 1920): 236,\n",
              " (1083, 719): 1,\n",
              " (1084, 666): 1,\n",
              " (1095, 873): 1,\n",
              " (1098, 702): 1,\n",
              " (1107, 765): 1,\n",
              " (1124, 1153): 1,\n",
              " (1125, 605): 1,\n",
              " (1125, 609): 1,\n",
              " (1125, 612): 1,\n",
              " (1125, 625): 1,\n",
              " (1125, 825): 1,\n",
              " (1125, 832): 2,\n",
              " (1125, 835): 1,\n",
              " (1125, 857): 1,\n",
              " (1125, 863): 1,\n",
              " (1125, 869): 1,\n",
              " (1125, 877): 1,\n",
              " (1125, 916): 1,\n",
              " (1125, 917): 1,\n",
              " (1125, 929): 1,\n",
              " (1125, 939): 1,\n",
              " (1125, 959): 1,\n",
              " (1125, 962): 1,\n",
              " (1125, 972): 1,\n",
              " (1125, 979): 1,\n",
              " (1125, 983): 1,\n",
              " (1125, 988): 1,\n",
              " (1125, 991): 1,\n",
              " (1125, 998): 1,\n",
              " (1125, 1002): 1,\n",
              " (1125, 1008): 1,\n",
              " (1125, 1014): 1,\n",
              " (1125, 1020): 1,\n",
              " (1125, 1027): 1,\n",
              " (1125, 1063): 1,\n",
              " (1125, 1069): 1,\n",
              " (1125, 1073): 1,\n",
              " (1125, 1082): 1,\n",
              " (1125, 1113): 1,\n",
              " (1125, 1114): 1,\n",
              " (1125, 1155): 1,\n",
              " (1125, 1189): 1,\n",
              " (1125, 1241): 1,\n",
              " (1128, 776): 1,\n",
              " (1129, 661): 1,\n",
              " (1130, 782): 1,\n",
              " (1152, 1548): 4,\n",
              " (1153, 749): 1,\n",
              " (1158, 268): 1,\n",
              " (1166, 808): 1,\n",
              " (1175, 719): 1,\n",
              " (1181, 691): 1,\n",
              " (1200, 675): 1,\n",
              " (1200, 798): 1,\n",
              " (1200, 800): 2,\n",
              " (1206, 574): 1,\n",
              " (1213, 693): 1,\n",
              " (1228, 560): 1,\n",
              " (1231, 765): 1,\n",
              " (1240, 736): 1,\n",
              " (1246, 710): 1,\n",
              " (1273, 614): 1,\n",
              " (1273, 616): 1,\n",
              " (1274, 614): 1,\n",
              " (1274, 615): 2,\n",
              " (1274, 617): 2,\n",
              " (1274, 618): 2,\n",
              " (1274, 619): 2,\n",
              " (1274, 621): 1,\n",
              " (1279, 587): 1,\n",
              " (1280, 532): 1,\n",
              " (1280, 604): 1,\n",
              " (1280, 613): 2,\n",
              " (1280, 615): 2,\n",
              " (1280, 616): 2,\n",
              " (1280, 618): 1,\n",
              " (1280, 620): 2,\n",
              " (1280, 631): 1,\n",
              " (1280, 674): 1,\n",
              " (1280, 720): 375,\n",
              " (1290, 634): 1,\n",
              " (1295, 728): 1,\n",
              " (1296, 682): 1,\n",
              " (1299, 859): 1,\n",
              " (1299, 862): 1,\n",
              " (1299, 865): 3,\n",
              " (1299, 867): 1,\n",
              " (1299, 868): 1,\n",
              " (1300, 674): 1,\n",
              " (1300, 700): 1,\n",
              " (1300, 728): 4,\n",
              " (1306, 422): 1,\n",
              " (1310, 570): 1,\n",
              " (1313, 615): 1,\n",
              " (1320, 716): 1,\n",
              " (1331, 609): 1,\n",
              " (1337, 535): 1,\n",
              " (1340, 560): 1,\n",
              " (1345, 715): 1,\n",
              " (1347, 435): 1,\n",
              " (1347, 457): 1,\n",
              " (1355, 445): 1,\n",
              " (1355, 737): 1,\n",
              " (1360, 569): 1,\n",
              " (1366, 689): 1,\n",
              " (1366, 768): 12,\n",
              " (1368, 802): 1,\n",
              " (1376, 662): 1,\n",
              " (1380, 687): 1,\n",
              " (1385, 669): 1,\n",
              " (1397, 649): 1,\n",
              " (1404, 691): 1,\n",
              " (1406, 670): 1,\n",
              " (1410, 668): 1,\n",
              " (1410, 734): 1,\n",
              " (1411, 419): 1,\n",
              " (1415, 933): 1,\n",
              " (1418, 556): 1,\n",
              " (1420, 560): 1,\n",
              " (1425, 545): 1,\n",
              " (1426, 576): 1,\n",
              " (1432, 670): 1,\n",
              " (1444, 730): 1,\n",
              " (1449, 641): 1,\n",
              " (1453, 635): 1,\n",
              " (1456, 454): 1,\n",
              " (1471, 671): 1,\n",
              " (1499, 475): 1,\n",
              " (1500, 1000): 1,\n",
              " (1510, 686): 1,\n",
              " (1524, 540): 1,\n",
              " (1536, 2048): 6,\n",
              " (1541, 523): 1,\n",
              " (1553, 823): 1,\n",
              " (1555, 1037): 1,\n",
              " (1589, 709): 1,\n",
              " (1599, 1064): 2,\n",
              " (1600, 1063): 1,\n",
              " (1603, 1027): 1,\n",
              " (1607, 937): 1,\n",
              " (1621, 959): 1,\n",
              " (1627, 983): 1,\n",
              " (1629, 965): 1,\n",
              " (1641, 973): 1,\n",
              " (1643, 955): 1,\n",
              " (1645, 975): 1,\n",
              " (1645, 987): 1,\n",
              " (1659, 1015): 1,\n",
              " (1664, 592): 1,\n",
              " (1670, 940): 1,\n",
              " (1671, 847): 1,\n",
              " (1673, 981): 1,\n",
              " (1675, 959): 1,\n",
              " (1679, 975): 1,\n",
              " (1679, 981): 1,\n",
              " (1679, 999): 1,\n",
              " (1680, 1080): 1,\n",
              " (1687, 999): 1,\n",
              " (1708, 692): 1,\n",
              " (1720, 676): 1,\n",
              " (1720, 780): 1,\n",
              " (1741, 809): 1,\n",
              " (1749, 811): 1,\n",
              " (1752, 783): 1,\n",
              " (1758, 842): 1,\n",
              " (1763, 855): 1,\n",
              " (1800, 1041): 1,\n",
              " (1804, 832): 1,\n",
              " (1805, 839): 1,\n",
              " (1827, 851): 1,\n",
              " (1829, 749): 1,\n",
              " (1835, 885): 1,\n",
              " (1837, 899): 1,\n",
              " (1848, 444): 1,\n",
              " (1861, 881): 1,\n",
              " (1875, 811): 1,\n",
              " (1877, 849): 1,\n",
              " (1877, 883): 1,\n",
              " (1879, 823): 1,\n",
              " (1879, 857): 1,\n",
              " (1879, 897): 1,\n",
              " (1885, 875): 1,\n",
              " (1889, 813): 1,\n",
              " (1889, 873): 1,\n",
              " (1889, 895): 1,\n",
              " (1891, 885): 1,\n",
              " (1895, 719): 1,\n",
              " (1895, 871): 1,\n",
              " (1895, 887): 1,\n",
              " (1900, 924): 1,\n",
              " (1901, 897): 1,\n",
              " (1905, 859): 1,\n",
              " (1905, 869): 1,\n",
              " (1905, 891): 2,\n",
              " (1905, 897): 1,\n",
              " (1905, 911): 1,\n",
              " (1906, 1080): 85,\n",
              " (1907, 889): 1,\n",
              " (1907, 915): 1,\n",
              " (1909, 859): 1,\n",
              " (1909, 883): 1,\n",
              " (1909, 885): 1,\n",
              " (1911, 803): 2,\n",
              " (1911, 805): 1,\n",
              " (1911, 807): 2,\n",
              " (1911, 811): 3,\n",
              " (1911, 873): 1,\n",
              " (1911, 899): 1,\n",
              " (1911, 913): 1,\n",
              " (1913, 889): 1,\n",
              " (1913, 891): 2,\n",
              " (1913, 901): 1,\n",
              " (1913, 903): 1,\n",
              " (1914, 896): 1,\n",
              " (1915, 903): 1,\n",
              " (1915, 911): 1,\n",
              " (1915, 1295): 1,\n",
              " (1917, 823): 1,\n",
              " (1917, 911): 1,\n",
              " (1917, 915): 1,\n",
              " (1919, 853): 1,\n",
              " (1920, 554): 1,\n",
              " (1920, 558): 1,\n",
              " (1920, 592): 1,\n",
              " (1920, 774): 1,\n",
              " (1920, 807): 1,\n",
              " (1920, 816): 1,\n",
              " (1920, 817): 3,\n",
              " (1920, 818): 1,\n",
              " (1920, 819): 1,\n",
              " (1920, 821): 1,\n",
              " (1920, 824): 2,\n",
              " (1920, 836): 1,\n",
              " (1920, 880): 1,\n",
              " (1920, 888): 1,\n",
              " (1920, 1080): 1028,\n",
              " (1920, 1930): 7,\n",
              " (1969, 1113): 1,\n",
              " (2021, 1273): 1,\n",
              " (2029, 1943): 1,\n",
              " (2048, 1536): 1,\n",
              " (2184, 1968): 1,\n",
              " (2213, 1701): 1,\n",
              " (2220, 1968): 1,\n",
              " (2241, 1569): 1,\n",
              " (2268, 3024): 3,\n",
              " (2304, 4096): 25,\n",
              " (2307, 1959): 1,\n",
              " (2373, 975): 1,\n",
              " (2448, 3264): 16,\n",
              " (2560, 1440): 7,\n",
              " (2605, 1861): 1,\n",
              " (2633, 1825): 1,\n",
              " (2642, 2839): 1,\n",
              " (2913, 3857): 1,\n",
              " (2926, 1417): 1,\n",
              " (2950, 1886): 1,\n",
              " (2958, 1985): 1,\n",
              " (2959, 2537): 1,\n",
              " (2959, 2679): 1,\n",
              " (2959, 4158): 1,\n",
              " (2961, 3937): 1,\n",
              " (2966, 2094): 1,\n",
              " (2975, 2896): 1,\n",
              " (2976, 3968): 3,\n",
              " (2983, 2537): 1,\n",
              " (2985, 3125): 1,\n",
              " (2991, 2207): 1,\n",
              " (2991, 2209): 1,\n",
              " (2999, 2385): 1,\n",
              " (2999, 2433): 1,\n",
              " (2999, 2481): 1,\n",
              " (3003, 3524): 1,\n",
              " (3007, 1905): 1,\n",
              " (3007, 2273): 1,\n",
              " (3007, 2503): 1,\n",
              " (3007, 2529): 1,\n",
              " (3007, 2625): 1,\n",
              " (3007, 3613): 1,\n",
              " (3023, 2777): 1,\n",
              " (3024, 4032): 92,\n",
              " (3264, 2448): 5,\n",
              " (3279, 1393): 1,\n",
              " (4032, 3024): 1,\n",
              " (4096, 2304): 49,\n",
              " (4160, 1456): 1,\n",
              " (4160, 1968): 7,\n",
              " (4160, 3120): 46}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szOyEAsFZUKv"
      },
      "source": [
        "def resize_images(file_list, width = 1024, height = 1024, overwrite = True, save_dir = ''):\n",
        "    total_files = len(file_list)\n",
        "    idx = 1\n",
        "    for path in file_list:\n",
        "        img = Image.open(path)\n",
        "        img_resized = img.resize((width, height))\n",
        "        if overwrite:\n",
        "            img_resized.save(path)\n",
        "            filename = path.split('/')[-1] \n",
        "            print(f\"{idx}/{total_files}: {filename} {img.size}--> ({width}x{height})\")\n",
        "        else:\n",
        "            filename = path.split('/')[-1]\n",
        "            img_resized.save(save_dir + filename)\n",
        "            print(f'{filename} saved to {save_dir}')\n",
        "        idx +=1\n",
        "    clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYVfpex0bino"
      },
      "source": [
        "resize_images(image_file_list , overwrite= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk9QNyGpXCNF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cevnPfbzvWj_"
      },
      "source": [
        "We don't have to resize the test images because they are already resized to our desired format. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbt_BTMJeU0b"
      },
      "source": [
        "<a id=\"5\"></a>\n",
        "## 5. Train and Validation Split\n",
        "For training the model and evaluating at the same time, we will split the whole training dataset into a train and validation set. We will be using $80-20$ dividion rule for the train and validation split. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqKag3boftfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286618dd-a1ea-4033-e4dd-880c207f8b8e"
      },
      "source": [
        "import random\n",
        "random.seed(401)\n",
        "\n",
        "#randomply selecting the index of the files\n",
        "valid_set_index = random.sample(range(len(image_file_list)), 500)\n",
        "len(set(image_file_list)), len(set(label_file_list_txt)), len(valid_set_index)\n",
        "\n",
        "image_file_list = sorted(image_file_list)\n",
        "label_file_list_txt = sorted(label_file_list_txt)\n",
        "\n",
        "# sanity check of the image files and labels being in the same order\n",
        "print('Checking files concurrency')\n",
        "print(image_file_list[:5])\n",
        "print(label_file_list_txt[:5])\n",
        "\n",
        "# code to separate train and validation set\n",
        "valid_selected_images = []\n",
        "valid_selected_labels = []\n",
        "\n",
        "for index in valid_set_index: \n",
        "    valid_selected_images.append(image_file_list[index])\n",
        "    valid_selected_labels.append(label_file_list_txt[index])\n",
        "\n",
        "\n",
        "print('\\n\\nChecking files concurrency in validation set')\n",
        "print(valid_selected_images[:5])\n",
        "print(valid_selected_labels[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking files concurrency\n",
            "['/content/train_data_raw/01.jpg', '/content/train_data_raw/02.jpg', '/content/train_data_raw/03.jpg', '/content/train_data_raw/04.jpg', '/content/train_data_raw/05.jpg']\n",
            "['/content/train_data_raw/01.txt', '/content/train_data_raw/02.txt', '/content/train_data_raw/03.txt', '/content/train_data_raw/04.txt', '/content/train_data_raw/05.txt']\n",
            "\n",
            "\n",
            "Checking files concurrency in validation set\n",
            "['/content/train_data_raw/Numan_(143).jpg', '/content/train_data_raw/Dipto_ 191.jpg', '/content/train_data_raw/Navid_635.JPG', '/content/train_data_raw/Dipto_852.jpg', '/content/train_data_raw/Numan_(44).jpg']\n",
            "['/content/train_data_raw/Numan_(143).txt', '/content/train_data_raw/Dipto_ 191.txt', '/content/train_data_raw/Navid_635.txt', '/content/train_data_raw/Dipto_852.txt', '/content/train_data_raw/Numan_(44).txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VreBCd8yh607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32833db5-65c7-4a03-f947-dc8747151b5b"
      },
      "source": [
        "import shutil\n",
        "\n",
        "# Creating validation directory\n",
        "valid_dir = '/content/valid/'\n",
        "\n",
        "if os.path.exists(valid_dir):\n",
        "    print(f'Directory {valid_dir} already exists !')\n",
        "else: \n",
        "    os.makedirs(valid_dir)\n",
        "    print(f\"Directory {valid_dir} is created successfully!\") \n",
        "\n",
        "\n",
        "for idx in range(len(valid_selected_images)):\n",
        "    # moving image files\n",
        "    mypath = valid_selected_images[idx]\n",
        "    if os.path.exists(mypath):\n",
        "        filename = mypath.split('/')[-1]\n",
        "        shutil.move(mypath , valid_dir + filename)\n",
        "    else:\n",
        "        print(f'{mypath} not found')\n",
        "        \n",
        "    # moving label files\n",
        "    mypath = valid_selected_labels[idx]\n",
        "    if os.path.exists(mypath):\n",
        "        filename = mypath.split('/')[-1]\n",
        "        shutil.move(mypath , valid_dir + filename)\n",
        "    else:\n",
        "        print(f'{mypath} not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory /content/valid/ is created successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n9M6O7oafRP"
      },
      "source": [
        "## **Augmentation using CLoDSA (Augmentation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUeICW7VafRQ"
      },
      "source": [
        "### Installing the necessary libraries\n",
        "\n",
        "In case that CLODSA is not installed in your system, the first task consists in installing it using ``pip``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IMnZaD7afRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d40682-504a-4c7a-935d-15bacbe23e2d"
      },
      "source": [
        "!pip install clodsa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting clodsa\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/bf/0e520d64a7bc2b01a19a9c41961c1caa7457e7f080eaee09d4cce229b254/clodsa-1.2.42.tar.gz\n",
            "Collecting mahotas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/3b/1f3fe2f86ffdb4a2fbc6baaf4ef0e6cebdd3e127de44ddd188dc2ed0d412/mahotas-1.4.11-cp36-cp36m-manylinux2010_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (from clodsa) (0.5.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from clodsa) (2.4.3)\n",
            "Collecting commentjson\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/76/c4aa9e408dbacee3f4de8e6c5417e5f55de7e62fb5a50300e1233a2c9cb5/commentjson-0.9.0.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from clodsa) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from clodsa) (2.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from clodsa) (1.18.5)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from clodsa) (3.38.0)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.6/dist-packages (from clodsa) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from clodsa) (0.17.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->clodsa) (3.13)\n",
            "Collecting lark-parser<0.8.0,>=0.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/b8/aa7d6cf2d5efdd2fcd85cf39b33584fe12a0f7086ed451176ceb7fb510eb/lark-parser-0.7.8.tar.gz (276kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->clodsa) (1.15.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->clodsa) (2.4.0)\n",
            "Building wheels for collected packages: clodsa, commentjson, lark-parser\n",
            "  Building wheel for clodsa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clodsa: filename=clodsa-1.2.42-py2.py3-none-any.whl size=72142 sha256=70a7452ca6dee11ceaebcad9cd2f679b16e9eecd09459b5f89e4546e103bb5b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/7c/f5/4caa95c8cf6a4ed959de7133a5a623ce0c9c4d134e57431204\n",
            "  Building wheel for commentjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for commentjson: filename=commentjson-0.9.0-cp36-none-any.whl size=12087 sha256=dce599114a7b5041151208b37070d3adaf3e3360d0803fd74debb0db30dc9d69\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/18/46/8da734185b844fc754de60da2c162fc15f7acdacfd4621144e\n",
            "  Building wheel for lark-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lark-parser: filename=lark_parser-0.7.8-py2.py3-none-any.whl size=62514 sha256=d94e690fcb16888a170303f59dad443bdf0d18e206f3884c532dd7adeb5c0f77\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a2/30/ebae6ffa73cf3aa1c972a24d4c78388afd910f91e43bf554aa\n",
            "Successfully built clodsa commentjson lark-parser\n",
            "Installing collected packages: mahotas, lark-parser, commentjson, clodsa\n",
            "Successfully installed clodsa-1.2.42 commentjson-0.9.0 lark-parser-0.7.8 mahotas-1.4.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxA9V3xGafRW"
      },
      "source": [
        "### Loading the necessary libraries\n",
        "\n",
        "The first step in the pipeline consists in loading the necessary libraries to apply the data augmentation techniques in CLODSA. We also load some libraries to show the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO1fejKIafRZ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from clodsa.augmentors.augmentorFactory import createAugmentor\n",
        "from clodsa.transformers.transformerFactory import transformerGenerator\n",
        "from clodsa.techniques.techniqueFactory import createTechnique\n",
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCeYyyjjyjXd"
      },
      "source": [
        "os.mkdir('xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBh7_7QhOQQp"
      },
      "source": [
        "import shutil\n",
        "\n",
        "directory = '/content/train_data_raw/'\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".xml\"):\n",
        "        shutil.move('/content/train_data_raw/'+ filename, '/content/xml/' + filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHr_tEW0eXLD"
      },
      "source": [
        "## **Replacing png with jpg**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ0VUbfQc7Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fa0aa4-e458-45a4-eeaf-737d86e5b8e2"
      },
      "source": [
        "!pip install image_to_numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting image_to_numpy\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/76/5f1068fe491b011e9625f1da73f2d5c00e9d810dce39253ba6bcf886ac79/image_to_numpy-1.0.0.tar.gz\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image_to_numpy) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from image_to_numpy) (1.18.5)\n",
            "Building wheels for collected packages: image-to-numpy\n",
            "  Building wheel for image-to-numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-to-numpy: filename=image_to_numpy-1.0.0-cp36-none-any.whl size=3474 sha256=acc090cad4ac9f692049edb8c24945f17268b5bc6bc5f479b1e0ea8b3f0362d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/f6/32/7d71a861b570d0faa8be3a04265809435f1aee4620ff4bdea1\n",
            "Successfully built image-to-numpy\n",
            "Installing collected packages: image-to-numpy\n",
            "Successfully installed image-to-numpy-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NlOzyOOCRv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83d56d9-52bb-459a-ecfa-01784e78e532"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "directory = 'train_data_raw'\n",
        "print(os.path.exists(directory))\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".png\") or filename.endswith(\".PNG\") or filename.endswith(\".jpeg\") or filename.endswith(\".JPEG\"): \n",
        "      img = os.path.join(directory, filename)\n",
        "      imagePath = img\n",
        "      img = cv2.imread(img)\n",
        "      img_name = directory+'/'+filename.split('.')[0] + '.jpg'\n",
        "      print(img_name)\n",
        "      # Save .jpg image\n",
        "      cv2.imwrite(img_name, img, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
        "      os.remove(imagePath)\n",
        "    else:\n",
        "      continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "train_data_raw/193.jpg\n",
            "train_data_raw/202.jpg\n",
            "train_data_raw/200.jpg\n",
            "train_data_raw/203.jpg\n",
            "train_data_raw/204.jpg\n",
            "train_data_raw/194.jpg\n",
            "train_data_raw/197.jpg\n",
            "train_data_raw/199.jpg\n",
            "train_data_raw/196.jpg\n",
            "train_data_raw/65.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2Dcj2u8d8Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d25691-b1ec-4766-a1eb-9eab3c273ab2"
      },
      "source": [
        "print(\"Number of images in the folder\")\n",
        "!ls -1 train_data_raw/*.jpg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the folder\n",
            "2387\n",
            "Number of annotations in the folder\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsLLx8lHeGQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5e447b-91d1-4a77-aedb-6e3425d2ba02"
      },
      "source": [
        "print(\"Number of images in the folder\")\n",
        "!ls -1 train_data_raw/*.jpg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.png | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.JPG | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.jpeg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the folder\n",
            "2387\n",
            "Number of annotations in the folder\n",
            "ls: cannot access 'train_data_raw/*.png': No such file or directory\n",
            "0\n",
            "Number of annotations in the folder\n",
            "113\n",
            "Number of annotations in the folder\n",
            "ls: cannot access 'train_data_raw/*.jpeg': No such file or directory\n",
            "0\n",
            "Number of annotations in the folder\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_0autm-afRe"
      },
      "source": [
        "### Creating the augmentor object\n",
        "\n",
        "As explained in the documentation of CLODSA, we need to specify some parameters for the augmentation process, and use them to create an augmentor object.  \n",
        "\n",
        "_The kind of problem_. In this case, we are working in a detection problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxz6HsATafRg"
      },
      "source": [
        "PROBLEM = \"detection\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6O4tVUPafRl"
      },
      "source": [
        "_The annotation mode_. We use the YOLO format. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNHRztstafRm"
      },
      "source": [
        "ANNOTATION_MODE = \"yolo\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiKYMZBYafRq"
      },
      "source": [
        "_The input path_. The input path containing the images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pzsCqaXafRs"
      },
      "source": [
        "INPUT_PATH = \"train_data_raw/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM6Kzl-OafRw"
      },
      "source": [
        "_The generation mode_. In this case, linear, that is, all the augmentation techniques are applied to all the images of the original dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tq04z7nafRx"
      },
      "source": [
        "GENERATION_MODE = \"linear\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQLgW6izafR1"
      },
      "source": [
        "_The output mode_. The generated images will be stored in a new folder called augmented_images.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUWyaD8rafR2"
      },
      "source": [
        "OUTPUT_MODE = \"yolo\"\n",
        "OUTPUT_PATH= \"train_data_raw_1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwV-nrdJafR5"
      },
      "source": [
        "Using the above information, we can create our augmentor object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTaCIQD-afR7"
      },
      "source": [
        "augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxoQQ3wFafSA"
      },
      "source": [
        "### Adding the augmentation techniques\n",
        "\n",
        "Now, we define the techniques that will be applied in our augmentation process and add them to our augmentor object. To illustrate the transformations, we will use the following image of the dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVnUVKZIafSH"
      },
      "source": [
        "Just for showing the results of applying data augmentation in an object detection problem, we define a function to read the annotations and another one to show them. This funcionality is not necessary when using CLODSA since it is already implemented in there. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWzxSnYPafSJ"
      },
      "source": [
        "def boxesFromYOLO(imagePath,labelPath):\n",
        "    image = cv2.imread(imagePath)\n",
        "    (hI, wI) = image.shape[:2]\n",
        "    lines = [line.rstrip('\\n') for line in open(labelPath)]\n",
        "    #if(len(objects)<1):\n",
        "    #    raise Exception(\"The xml should contain at least one object\")\n",
        "    boxes = []\n",
        "    if lines != ['']:\n",
        "        for line in lines:\n",
        "            components = line.split(\" \")\n",
        "            category = components[0]\n",
        "            x  = int(float(components[1])*wI - float(components[3])*wI/2)\n",
        "            y = int(float(components[2])*hI - float(components[4])*hI/2)\n",
        "            h = int(float(components[4])*hI)\n",
        "            w = int(float(components[3])*wI)\n",
        "            boxes.append((category, (x, y, w, h)))\n",
        "    return (image,boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4_Jmo5NafSM"
      },
      "source": [
        "categoriesColors = {11: (255,0,0),14:(0,0,255)}\n",
        "\n",
        "def showBoxes(image,boxes):\n",
        "    cloneImg = image.copy()\n",
        "    for box in boxes:\n",
        "        if(len(box)==2):\n",
        "            (category, (x, y, w, h))=box\n",
        "        else:\n",
        "            (category, (x, y, w, h),_)=box\n",
        "        if int(category) in categoriesColors.keys():\n",
        "            cv2.rectangle(cloneImg,(x,y),(x+w,y+h),categoriesColors[int(category)],5)\n",
        "        else:\n",
        "            cv2.rectangle(cloneImg,(x,y),(x+w,y+h),(0,255,0),5)\n",
        "    plt.imshow(cloneImg[:,:,::-1])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUc0j53dafSO"
      },
      "source": [
        "Now, we show the annotation of the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LbgLFG_OKNV"
      },
      "source": [
        "First of all, we must define a transformer generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-THZ749OKNW"
      },
      "source": [
        "transformer = transformerGenerator(PROBLEM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZzS82tnafSw"
      },
      "source": [
        "#### Rotation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ7eV97aafSx"
      },
      "source": [
        "rotate10 = createTechnique(\"rotate\", {\"angle\" :10})\n",
        "augmentor.addTransformer(transformer(rotate10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD4ha5WnDtnx"
      },
      "source": [
        "#### Blurring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSV4AmluDtny"
      },
      "source": [
        "Blurring5 = createTechnique(\"blurring\", {\"ksize\" : 5})\n",
        "augmentor.addTransformer(transformer(Blurring5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvNvLOCZFeqO"
      },
      "source": [
        "#### Gaussian Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zimINznuFeqP"
      },
      "source": [
        "gaussNoise1025 = createTechnique(\"gaussian_noise\", {\"mean\" : 10,\"sigma\":25})\n",
        "augmentor.addTransformer(transformer(gaussNoise1025))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA4Bv2x4GPVt"
      },
      "source": [
        "#### Shearing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PErRWdTsGPVv"
      },
      "source": [
        "Shearing1 = createTechnique(\"shearing\", {\"a\":0.1})\n",
        "augmentor.addTransformer(transformer(Shearing1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouZ-I-DbafTO"
      },
      "source": [
        "### Applying the augmentation process\n",
        "\n",
        "Finally, we apply the augmentation process (this might take some time depending on the number of images of the original dataset and the number of transformations that will be applied). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NDRkKtSWiS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53de8b2-559f-4e9b-e986-6f9caee3299f"
      },
      "source": [
        "print(\"Number of images in the folder\")\n",
        "!ls -1 train_data_raw/*.jpg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw/*.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the folder\n",
            "2387\n",
            "Number of annotations in the folder\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owRG290NafTO"
      },
      "source": [
        "augmentor.applyAugmentation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZydpyBjTafTT"
      },
      "source": [
        "Finally, we can check the amount of images in the output folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atu1eEVUafTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272ac516-fe88-4d58-d548-4119180be3fb"
      },
      "source": [
        "print(\"Number of images in the folder\")\n",
        "!ls -1 train_data_raw_1/*.jpg | wc -l\n",
        "print(\"Number of annotations in the folder\")\n",
        "!ls -1 train_data_raw_1/*.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the folder\n",
            "9548\n",
            "Number of annotations in the folder\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkKxdCIvSWJE"
      },
      "source": [
        "import shutil\n",
        "\n",
        "directory = '/content/train_data_raw_1/'\n",
        "for filename in os.listdir(directory):\n",
        "    shutil.move('/content/train_data_raw_1/'+ filename, '/content/train_data_raw/' + filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFO3_FJFlnWn"
      },
      "source": [
        "Now the remaining images in the `train_data_raw` are actually the train directory. We will rename it to `train`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q06b7JHfGDOV"
      },
      "source": [
        "!mv train_data_raw train  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYiGNesTl6pv"
      },
      "source": [
        "<a id=\"6\"></a>\n",
        "## 6. Creating Metadata:\n",
        "The strter code has some files as metadata. We need to produce contents for them. We have to produce the follwoing files. \n",
        "* `train.txt` : A text file containing full paths of all the training image files. \n",
        "* `valid.txt` : A text file containing full paths of all the validation image files\n",
        "* `test.txt` :  A text file containing full paths of all the test image files\n",
        "* `traffic.names`: A text file containing all the traffic label names line by line\n",
        "* `traffic.data`: Its a confguration file that stores the number of classes, and the location of train.txt and valid.txt for training purpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxswYWFT_3Xf"
      },
      "source": [
        "def lookup_image_file_paths(formats, dir):\n",
        "    \"\"\"\n",
        "    This function takes a specified set of formats and directory address to list all the filepaths\n",
        "    of the desired format in that directory\n",
        "    \"\"\"\n",
        "    filepaths = []\n",
        "    for format in formats:\n",
        "        filepaths.extend(glob.glob(f'{dir}*.{format}'))\n",
        "    return filepaths\n",
        "\n",
        "def make_txt_file(formats, dir):\n",
        "    \"\"\"\n",
        "    Formats the file names to write in the desired txt file\n",
        "    \"\"\"\n",
        "    filepaths = lookup_image_file_paths(formats, dir)\n",
        "    \n",
        "    filenames = [x.split('/')[-1] for x in filepaths]\n",
        "    txt_file_name = dir.split('/')[-2]\n",
        "\n",
        "    print(f'{txt_file_name} : {len(filepaths)} images')\n",
        "    with open(f'/content/metadata/{txt_file_name}.txt', 'w') as outfile:\n",
        "        for filename in filenames:\n",
        "            outfile.write(f'data/{txt_file_name}/'+filename+'\\n')\n",
        "        outfile.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7wAl-0yr3kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad02ac4-fcb0-48ca-be89-601d1587a0ad"
      },
      "source": [
        "train_dir = '/content/train/'\n",
        "valid_dir = '/content/valid/'\n",
        "test_dir =  '/content/test/'\n",
        "!mkdir metadata\n",
        "\n",
        "# Making the .txt file containing list of images. \n",
        "make_txt_file(formats, dir = train_dir)\n",
        "make_txt_file(formats, dir = test_dir)\n",
        "make_txt_file(formats, dir = valid_dir)\n",
        "\n",
        "# Writing the file traffic.names\n",
        "object_labels = list(lut.keys())\n",
        "with open('/content/metadata/traffic.names', 'w') as outfile:\n",
        "    for label in object_labels:\n",
        "        outfile.write(label + '\\n')\n",
        "    outfile.close()\n",
        "\n",
        "# Writing the file traffic.data\n",
        "data_config = f'classes=21\\ntrain=train.txt\\nvalid=valid.txt\\nnames=traffic.names'\n",
        "with open('/content/metadata/traffic.data', 'w') as outfile:\n",
        "    outfile.write(data_config + '\\n')\n",
        "    outfile.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : 12500 images\n",
            "test : 500 images\n",
            "valid : 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiFhIDozx0Pv"
      },
      "source": [
        "<a id=\"7\"></a>\n",
        "## 7. Saving the Processed Dataset:\n",
        "Now our dataset is ready for using with the starter code given at the host site. But before that we need to save the processed dataset in google drive so that we can later use it in the Starter Code. \n",
        "\n",
        "<font color='red'> Now mount your google drive here so that you can export the processed `dhaka-traffic-yolo-v3.zip` to your drive for later use </font> Or you can just download it and again re upload it to the Starter Notebook in Google Colab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxY-Cdol9Kih"
      },
      "source": [
        "!zip -r dhaka-traffic-yolo-v3_seed_401_partial_aug_.zip train test valid metadata\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79jyZED8eW4W"
      },
      "source": [
        "shutil.rmtree('test')\n",
        "shutil.rmtree('train')\n",
        "shutil.rmtree('valid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R4BCpEGKGhF"
      },
      "source": [
        "!cp dhaka-traffic-yolo-v3_seed_401_partial_aug_.zip '/content/drive/My Drive/Hisham Vaia/DhakaAI 2020/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0toF9pJzTba"
      },
      "source": [
        "Now we are done with pre-processing the data and we are ready to put the whole dataset to the training of Yolo V3 in the Starter Code given on the host website. \n",
        "\n",
        "Thank you and good luck!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}